import re
import io
from datetime import datetime, timezone
from pathlib import Path

import pandas as pd
import streamlit as st
import plotly.express as px

# =========================
# App Meta (Ø­Ù‚ÙˆÙ‚ + About)
# =========================
APP_TITLE = "Ù…Ø±Ø§Ù‚Ø¨ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©"
APP_SUBTITLE = "EGX Liquidity Monitor Dashboard"
APP_VERSION = "1.1.2"
AUTHOR = "Mahmoud Abdrabbo"
COPYRIGHT = f"Â© 2026 {AUTHOR}. All rights reserved."
DISCLAIMER = "Ù‡Ø°Ø§ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ù„Ø£ØºØ±Ø§Ø¶ Ù…Ø¹Ù„ÙˆÙ…Ø§ØªÙŠØ© ÙÙ‚Ø· ÙˆÙ„Ø§ ÙŠÙØ¹Ø¯ ØªÙˆØµÙŠØ© Ø§Ø³ØªØ«Ù…Ø§Ø±ÙŠØ©."

WHATSAPP_URL = "https://wa.me/qr/37OH2UF3VH7PM1"
TELEGRAM_URL = "https://t.me/Mahmoud_abdrabbo"
EMAIL = "mahmoud_elshaeer@yahoo.com"

st.set_page_config(page_title=APP_TITLE, layout="wide")

PROJECT_DIR = Path(__file__).resolve().parent
README_PATH = PROJECT_DIR / "README.md"

CSV_PATH  = PROJECT_DIR / "liquidity_all.csv"
XLSX_PATH = PROJECT_DIR / "liquidity_all.xlsx"  # fallback

# =========================
# Colors (Ø«Ø§Ø¨ØªØ©)
# =========================
GREEN = "#00C853"
RED   = "#D50000"
SIGN_COLOR_MAP = {"Ù…ÙˆØ¬Ø¨": GREEN, "Ø³Ø§Ù„Ø¨": RED}

# =========================
# CSS (ØªÙƒØ¨ÙŠØ± Ø§Ù„ØªØ§Ø¨Ø§Øª + Ø¹Ù†Ø§ÙˆÙŠÙ†)
# =========================
st.markdown(
    """
    <style>
    div[data-baseweb="tab"] > button {
        font-size: 26px !important;
        font-weight: 800 !important;
        padding-top: 12px !important;
        padding-bottom: 12px !important;
    }
    h1 { font-size: 42px !important; }
    h2 { font-size: 32px !important; }
    h3 { font-size: 26px !important; }
    </style>
    """,
    unsafe_allow_html=True
)

# =========================
# Ø§Ø³Ù…Ø§Ø¡ Ù…ØµØ­Ø­Ø© Ø­Ø³Ø¨ Ø§Ù„Ø±Ù…Ø² (Overrides)
# =========================
NAME_OVERRIDES = {
    "COMI": "Ø§Ù„Ø¨Ù†Ùƒ Ø§Ù„ØªØ¬Ø§Ø±ÙŠ Ø§Ù„Ø¯ÙˆÙ„ÙŠ",
    "HDBK": "Ø¨Ù†Ùƒ Ø§Ù„ØªØ¹Ù…ÙŠØ± ÙˆØ§Ù„Ø¥Ø³ÙƒØ§Ù†",
    "ADIB": "Ù…ØµØ±Ù Ø£Ø¨ÙˆØ¸Ø¨ÙŠ Ø§Ù„Ø¥Ø³Ù„Ø§Ù…ÙŠ",
    "CCAP": "Ø§Ù„Ù‚Ù„Ø¹Ø©",
    "CLHO": "Ù…Ø³ØªØ´ÙÙ‰ ÙƒÙ„ÙŠÙˆØ¨Ø§ØªØ±Ø§",
    "EAST": "Ø¥ÙŠØ³ØªØ±Ù† ÙƒÙˆÙ…Ø¨Ø§Ù†ÙŠ",
    "FWRY": "ÙÙˆØ±ÙŠ",
    "BTFH": "Ø¨Ù„ØªÙˆÙ† Ø§Ù„Ù‚Ø§Ø¨Ø¶Ø©",
    "ACAMD": "Ø§Ù„Ø´Ø±ÙƒØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù„Ø¥Ø¯Ø§Ø±Ø© ÙˆØªØ·ÙˆÙŠØ± Ø§Ù„Ø£ØµÙˆÙ„",
    "ABUK": "Ø£Ø¨ÙˆÙ‚ÙŠØ± Ù„Ù„Ø£Ø³Ù…Ø¯Ø©",
    "TAQA": "Ø·Ø§Ù‚Ø© Ø¹Ø±Ø¨ÙŠØ©",
    "TMGH": "Ø·Ù„Ø¹Øª Ù…ØµØ·ÙÙ‰",
    "HRHO": "Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¥ÙŠ Ø¥Ù Ø¬ÙŠ Ø§Ù„Ù‚Ø§Ø¨Ø¶Ø©",
    "HELI": "Ù…ØµØ± Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ù„Ù„Ø¥Ø³ÙƒØ§Ù†",
    "ETRS": "Ø¥ÙŠØ¬ÙŠØªØ±Ø§Ù†Ø³",
    "ZEOT": "Ø§Ù„Ø²ÙŠÙˆØª Ø§Ù„Ù…Ø³ØªØ®Ù„ØµØ©",
    "ORAS": "Ø£ÙˆØ±Ø§Ø³ÙƒÙˆÙ… Ù„Ù„Ø¥Ù†Ø´Ø§Ø¡",
    "EGAL": "Ù…ØµØ± Ù„Ù„Ø£Ù„ÙˆÙ…Ù†ÙŠÙˆÙ…",
    "CRST": "ÙƒØ±Ø³ØªÙ…Ø§Ø±Ùƒ Ù„Ù„Ù…Ù‚Ø§ÙˆÙ„Ø§Øª",
    "OIH": "Ø£ÙˆØ±Ø§Ø³ÙƒÙˆÙ… Ù„Ù„Ø§Ø³ØªØ«Ù…Ø§Ø± Ø§Ù„Ù‚Ø§Ø¨Ø¶Ø©",
    "MFPC": "Ù…ÙˆØ¨ÙƒÙˆ",
    "ISMQ": "Ø§Ù„Ø­Ø¯ÙŠØ¯ ÙˆØ§Ù„ØµÙ„Ø¨ Ù„Ù„Ù…Ù†Ø§Ø¬Ù… ÙˆØ§Ù„Ù…Ø­Ø§Ø¬Ø±",
    "EGCH": "ÙƒÙŠÙ…Ø§",
    "NCCW": "Ø§Ù„Ù†ØµØ± Ù„Ù„Ø£Ø¹Ù…Ø§Ù„ Ø§Ù„Ù…Ø¯Ù†ÙŠØ©",
    "AMER": "Ø¹Ø§Ù…Ø± Ø¬Ø±ÙˆØ¨",
    "PHGC": "Ø¨Ø±ÙŠÙ…ÙŠÙ… Ù‡ÙŠÙ„Ø«ÙƒÙŠØ± Ø¬Ø±ÙˆØ¨",
    "PHDC": "Ø¨Ø§Ù„Ù… Ù‡ÙŠÙ„Ø²",
    "RAYA": "Ø±Ø§ÙŠØ©",
    "ARAB": "Ø§Ù„Ù…Ø·ÙˆØ±ÙˆÙ† Ø§Ù„Ø¹Ø±Ø¨ Ø§Ù„Ù‚Ø§Ø¨Ø¶Ø©",
}

# =========================
# ØªÙ†Ø¸ÙŠÙ/ØªØ·Ø¨ÙŠØ¹ Ø¹Ø±Ø¨ÙŠ
# =========================
ARABIC_TATWEEL = "\u0640"
ARABIC_DIACRITICS_RE = re.compile(r"[\u0617-\u061A\u064B-\u0652]")

def is_arabic_char(ch: str) -> bool:
    return "\u0600" <= ch <= "\u06FF"

def normalize_arabic_name(s: str) -> str:
    if s is None or (isinstance(s, float) and pd.isna(s)):
        return ""
    s = str(s)

    # Ø¥Ø²Ø§Ù„Ø© Ø§ØªØ¬Ø§Ù‡/Ø±Ù…ÙˆØ² Ø®ÙÙŠØ©
    s = (s.replace("\u200f", "")
           .replace("\u200e", "")
           .replace("\u202b", "")
           .replace("\u202a", "")
           .replace("\xa0", " ")
           .replace(ARABIC_TATWEEL, "")
    )

    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªØ´ÙƒÙŠÙ„
    s = ARABIC_DIACRITICS_RE.sub("", s)

    # ØªÙˆØ­ÙŠØ¯ Ù…Ø³Ø§ÙØ§Øª
    s = re.sub(r"\s+", " ", s).strip()

    # Ø¯Ù…Ø¬ Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ù„ÙŠ Ø§Ù„Ù€ OCR ÙØµÙ„Ù‡Ø§
    tokens = s.split(" ")
    merged = []
    for tok in tokens:
        if len(tok) == 1 and merged and is_arabic_char(tok) and all(is_arabic_char(c) for c in merged[-1][-1:]):
            merged[-1] = merged[-1] + tok
        else:
            merged.append(tok)
    s = " ".join(merged)

    # Ø¥ØµÙ„Ø§Ø­Ø§Øª OCR Ø´Ø§Ø¦Ø¹Ø©
    fixes = [
        ("Ù…Ø±ØµÙ", "Ù…ØµØ±Ù"),
        ("Ù…Ø±Øµ", "Ù…ØµØ±"),
        ("Ù…Ø³ØªØ´Ù", "Ù…Ø³ØªØ´ÙÙ‰"),
        ("ÙˆØ§Ø¥", "ÙˆØ§Ù„Ø¥"),
        ("Ø§Ø¥", "Ø§Ù„Ø¥"),
        ("Ø§Ø§Ù„", "Ø§Ù„"),
        ("Ø§ÙŠØ³Øª  Ù†", "Ø§ÙŠØ³ØªØ±Ù†"),
        ("ÙƒÙˆÙ…Ø¨Ø§Ø¦Ù†ÙŠ", "ÙƒÙˆÙ…Ø¨Ø§Ù†ÙŠ"),
        ("ÙƒÙˆÙ…Ø¨Ø§Ù† ÙŠ", "ÙƒÙˆÙ…Ø¨Ø§Ù†ÙŠ"),
    ]
    for a, b in fixes:
        s = s.replace(a, b)

    return s.strip()

# =========================
# CSV reading (safe encodings)
# =========================
def read_csv_safe_path(path: Path) -> pd.DataFrame:
    for enc in ("utf-8-sig", "cp1256", "utf-8"):
        try:
            return pd.read_csv(path, encoding=enc)
        except UnicodeDecodeError:
            continue
    return pd.read_csv(path)

def read_csv_safe_bytes(b: bytes) -> pd.DataFrame:
    for enc in ("utf-8-sig", "cp1256", "utf-8"):
        try:
            return pd.read_csv(io.BytesIO(b), encoding=enc)
        except UnicodeDecodeError:
            continue
    return pd.read_csv(io.BytesIO(b))

# =========================
# Unify + Validate
# =========================
def load_data_df(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = df.columns.astype(str).str.strip()

    df = df.rename(columns={
        "ØµØ§ÙÙ‰ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©": "ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©",
        "Ø£Ø®Ø± Ø³Ø¹Ø±": "Ø¢Ø®Ø± Ø³Ø¹Ø±",
        "% Ù…Ø®Ø·Ø· Ø§Ù„Ø³ÙŠÙˆÙ„Ø©": "Ù†Ø³Ø¨Ø© Ù…Ø®Ø·Ø· Ø§Ù„Ø³ÙŠÙˆÙ„Ø©",
        "Ø§Ù„ØªØºÙŠØ±%": "Ø§Ù„ØªØºÙŠØ± %",
        "Ø§Ù„ØªØºÙŠØ± % ": "Ø§Ù„ØªØºÙŠØ± %",
        "Ø§Ù„Ø§Ø³Ù…": "Ø§Ù„Ø¥Ø³Ù…",
    })

    required = ["Ø§Ù„ØªØ§Ø±ÙŠØ®", "Ø§Ù„Ø±Ù…Ø²", "Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ø§Ù„Ø¯Ø§Ø®Ù„Ø©", "Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ø§Ù„Ø®Ø§Ø±Ø¬Ø©", "ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©"]
    missing = [c for c in required if c not in df.columns]
    if missing:
        raise ValueError(f"Ø£Ø¹Ù…Ø¯Ø© Ù†Ø§Ù‚ØµØ© ÙÙŠ Ø§Ù„Ù…Ù„Ù: {missing}")

    # ØªØ§Ø±ÙŠØ®
    df["Ø§Ù„ØªØ§Ø±ÙŠØ®"] = pd.to_datetime(df["Ø§Ù„ØªØ§Ø±ÙŠØ®"], errors="coerce")

    # ØªØ­ÙˆÙŠÙ„ Ø£Ø±Ù‚Ø§Ù…
    num_cols = [
        "Ø¢Ø®Ø± Ø³Ø¹Ø±", "Ø§Ù„ØªØºÙŠØ± %", "Ù‚ÙŠÙ…Ø© Ø§Ù„ØªØ¯Ø§ÙˆÙ„",
        "Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ø§Ù„Ø¯Ø§Ø®Ù„Ø©", "Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ø§Ù„Ø®Ø§Ø±Ø¬Ø©", "ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©",
        "Ù†Ø³Ø¨Ø© Ù…Ø®Ø·Ø· Ø§Ù„Ø³ÙŠÙˆÙ„Ø©", "Ø±Ù‚Ù… Ø§Ù„ØµÙØ­Ø©"
    ]
    for c in num_cols:
        if c in df.columns:
            df[c] = df[c].astype(str).str.replace(",", "", regex=False).str.strip()
            df[c] = pd.to_numeric(df[c], errors="coerce")

    before = len(df)
    df = df.dropna(subset=["Ø§Ù„ØªØ§Ø±ÙŠØ®", "Ø§Ù„Ø±Ù…Ø²"]).copy()
    if len(df) == 0:
        raise ValueError(
            "Ø¨Ø¹Ø¯ ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªØ§Ø±ÙŠØ®/Ø§Ù„Ø±Ù…Ø² Ø£ØµØ¨Ø­Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙØ§Ø±ØºØ©. "
            "Ø±Ø§Ø¬Ø¹ Ø¹Ù…ÙˆØ¯ 'Ø§Ù„ØªØ§Ø±ÙŠØ®' ÙˆØªÙ†Ø³ÙŠÙ‚Ù‡ ÙÙŠ Ø§Ù„Ù…Ù„Ù. "
            f"(Ù‚Ø¨Ù„ Ø§Ù„ØªÙ†Ø¸ÙŠÙ: {before} ØµÙ)"
        )

    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© + Overrides
    if "Ø§Ù„Ø¥Ø³Ù…" in df.columns:
        df["Ø§Ø³Ù…_Ù…Ù†Ø¸Ù"] = df["Ø§Ù„Ø¥Ø³Ù…"].apply(normalize_arabic_name)
    else:
        df["Ø§Ø³Ù…_Ù…Ù†Ø¸Ù"] = ""

    df["Ø§Ø³Ù…_Ù†Ù‡Ø§Ø¦ÙŠ"] = df.apply(
        lambda r: NAME_OVERRIDES.get(str(r["Ø§Ù„Ø±Ù…Ø²"]).strip(), r["Ø§Ø³Ù…_Ù…Ù†Ø¸Ù"]),
        axis=1
    )
    df["Ø§Ø³Ù…_Ù†Ù‡Ø§Ø¦ÙŠ"] = df["Ø§Ø³Ù…_Ù†Ù‡Ø§Ø¦ÙŠ"].fillna("").astype(str).str.strip()
    return df

def file_signature(path: Path) -> tuple:
    st_ = path.stat()
    return (int(st_.st_mtime_ns), int(st_.st_size))

@st.cache_data(show_spinner=False)
def load_data_from_csv(path_str: str, sig: tuple) -> pd.DataFrame:
    _ = sig  # cache-bust
    df = read_csv_safe_path(Path(path_str))
    return load_data_df(df)

@st.cache_data(show_spinner=False)
def load_data_from_excel(path_str: str, sig: tuple) -> pd.DataFrame:
    _ = sig  # cache-bust
    df = pd.read_excel(path_str)
    return load_data_df(df)

# =========================
# Helpers
# =========================
def fmt_money(x):
    if x is None or pd.isna(x):
        return "-"
    x = float(x)
    sign = "-" if x < 0 else ""
    x = abs(x)
    if x >= 1e9:  return f"{sign}{x/1e9:.2f}B"
    if x >= 1e6:  return f"{sign}{x/1e6:.2f}M"
    if x >= 1e3:  return f"{sign}{x/1e3:.2f}K"
    return f"{sign}{x:.0f}"

def consecutive_positive_days(df_sym):
    s = df_sym.sort_values("Ø§Ù„ØªØ§Ø±ÙŠØ®")["ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©"].fillna(0).tolist()
    cnt = 0
    for v in reversed(s):
        if v > 0:
            cnt += 1
        else:
            break
    return cnt

def style_net_column(v):
    if pd.isna(v):
        return ""
    if v > 0:
        return f"color: {GREEN}; font-weight: 800;"
    if v < 0:
        return f"color: {RED}; font-weight: 800;"
    return ""

def weighted_mean(values, weights):
    v = pd.to_numeric(values, errors="coerce")
    w = pd.to_numeric(weights, errors="coerce")
    mask = v.notna() & w.notna() & (w > 0)
    if mask.sum() == 0:
        return None
    return float((v[mask] * w[mask]).sum() / w[mask].sum())

def get_change_metric(scope_df: pd.DataFrame, mode: str):
    if "Ø§Ù„ØªØºÙŠØ± %" not in scope_df.columns or scope_df.empty:
        return "-", None

    if mode == "Ø¢Ø®Ø± Ø¬Ù„Ø³Ø©":
        last_row = scope_df.sort_values("Ø§Ù„ØªØ§Ø±ÙŠØ®").iloc[-1]
        v = last_row.get("Ø§Ù„ØªØºÙŠØ± %")
        return ("-" if pd.isna(v) else f"{v:.2f}%"), None

    if mode == "Ù…ØªÙˆØ³Ø·":
        v = scope_df["Ø§Ù„ØªØºÙŠØ± %"].mean()
        if pd.isna(v):
            return "-", None
        last_v = scope_df.sort_values("Ø§Ù„ØªØ§Ø±ÙŠØ®").iloc[-1].get("Ø§Ù„ØªØºÙŠØ± %")
        delta = f"Ø¢Ø®Ø± Ø¬Ù„Ø³Ø©: {last_v:.2f}%" if not pd.isna(last_v) else None
        return f"{v:.2f}%", delta

    if mode == "Ù…ØªÙˆØ³Ø· Ù…Ø±Ø¬Ù‘Ø­ (Ù‚ÙŠÙ…Ø© Ø§Ù„ØªØ¯Ø§ÙˆÙ„)":
        if "Ù‚ÙŠÙ…Ø© Ø§Ù„ØªØ¯Ø§ÙˆÙ„" not in scope_df.columns:
            return "-", None
        v = weighted_mean(scope_df["Ø§Ù„ØªØºÙŠØ± %"], scope_df["Ù‚ÙŠÙ…Ø© Ø§Ù„ØªØ¯Ø§ÙˆÙ„"])
        if v is None:
            return "-", None
        last_v = scope_df.sort_values("Ø§Ù„ØªØ§Ø±ÙŠØ®").iloc[-1].get("Ø§Ù„ØªØºÙŠØ± %")
        delta = f"Ø¢Ø®Ø± Ø¬Ù„Ø³Ø©: {last_v:.2f}%" if not pd.isna(last_v) else None
        return f"{v:.2f}%", delta

    return "-", None

def add_watermark(fig, text=COPYRIGHT):
    fig.add_annotation(
        text=text,
        xref="paper", yref="paper",
        x=0.99, y=0.01,
        xanchor="right",
        yanchor="bottom",
        showarrow=False,
        opacity=0.35,
        font=dict(size=12),
    )
    return fig

def fmt_dt(ts: float) -> str:
    dt = datetime.fromtimestamp(ts, tz=timezone.utc).astimezone()
    return dt.strftime("%Y-%m-%d %H:%M:%S %Z")

# =========================
# Header
# =========================
st.title(f"ğŸ“Š {APP_TITLE}")
st.caption(f"{APP_SUBTITLE} â€” Version {APP_VERSION} â€” {COPYRIGHT}")

# =========================
# Sidebar: refresh + debug
# =========================
with st.sidebar:
    st.markdown("### âš™ï¸ Ø£Ø¯ÙˆØ§Øª")
    if st.button("ğŸ”„ ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¢Ù† (Ù…Ø³Ø­ Ø§Ù„ÙƒØ§Ø´)", key="btn_refresh"):
        st.cache_data.clear()
        st.rerun()
    st.markdown("---")
    st.markdown("### ğŸ§ª ØªØ´Ø®ÙŠØµ Ø³Ø±ÙŠØ¹")

# =========================
# Load data (CSV first, XLSX fallback, else upload)
# =========================
df = None
data_source = None
data_path = None
data_mtime = None
data_size = None

try:
    if CSV_PATH.exists():
        sig = file_signature(CSV_PATH)
        df = load_data_from_csv(str(CSV_PATH), sig)
        data_source = "CSV"
        data_path = str(CSV_PATH)
        data_mtime = CSV_PATH.stat().st_mtime
        data_size = CSV_PATH.stat().st_size

    elif XLSX_PATH.exists():
        sig = file_signature(XLSX_PATH)
        df = load_data_from_excel(str(XLSX_PATH), sig)
        data_source = "XLSX (fallback)"
        data_path = str(XLSX_PATH)
        data_mtime = XLSX_PATH.stat().st_mtime
        data_size = XLSX_PATH.stat().st_size

    else:
        st.warning("Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø®Ù„ Ø§Ù„Ø±ÙŠØ¨Ùˆ. Ø§Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù Ù…Ù† Ù‡Ù†Ø§.")
        up = st.file_uploader("Upload liquidity_all.csv Ø£Ùˆ liquidity_all.xlsx", type=["csv", "xlsx"], key="uploader_data")
        if up is None:
            st.stop()

        if up.name.lower().endswith(".csv"):
            tmp = read_csv_safe_bytes(up.getvalue())
            df = load_data_df(tmp)
            data_source = "Uploaded CSV"
        else:
            tmp = pd.read_excel(up.getvalue())
            df = load_data_df(tmp)
            data_source = "Uploaded XLSX"

except Exception as e:
    st.error(f"ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {type(e).__name__}: {e}")
    st.stop()

# Sidebar debug
with st.sidebar:
    st.write(f"**Ø§Ù„Ù…ØµØ¯Ø±:** {data_source}")
    if data_path:
        st.write(f"**Ø§Ù„Ù…Ù„Ù:** `{Path(data_path).name}`")
        st.write(f"**Ø§Ù„Ø­Ø¬Ù…:** {data_size:,} bytes")
        st.write(f"**Ø¢Ø®Ø± ØªØ¹Ø¯ÙŠÙ„:** {fmt_dt(data_mtime)}")
    st.write(f"**Rows:** {len(df):,}")
    st.write(f"**Date range:** {df['Ø§Ù„ØªØ§Ø±ÙŠØ®'].min().date()} â†’ {df['Ø§Ù„ØªØ§Ø±ÙŠØ®'].max().date()}")
    with st.expander("ğŸ” Preview (Ø£ÙˆÙ„ 10 ØµÙÙˆÙ)"):
        st.dataframe(df.head(10), use_container_width=True, key="preview_df")

def trading_dates(df_: pd.DataFrame):
    return sorted(df_["Ø§Ù„ØªØ§Ø±ÙŠØ®"].dropna().dt.date.unique().tolist())

def last_n_sessions_range(df_: pd.DataFrame, n: int):
    dates = trading_dates(df_)
    if not dates:
        return None, None
    n = max(1, int(n))
    tail = dates[-n:] if len(dates) >= n else dates
    return tail[0], tail[-1]

def ytd_range(df_: pd.DataFrame):
    dates = trading_dates(df_)
    if not dates:
        return None, None
    last_day = dates[-1]
    y0 = last_day.replace(month=1, day=1)
    start = next((d for d in dates if d >= y0), dates[0])
    return start, last_day

def apply_quick_range(df_: pd.DataFrame, option: str, min_date, max_date):
    # ÙŠØ±Ø¬Ù‘Ø¹ (start_date, end_date) ÙƒÙ€ date
    if option == "Ù…Ø®ØµØµ":
        return None, None

    if option == "Ø¢Ø®Ø± ÙŠÙˆÙ… (Ø¢Ø®Ø± Ø¬Ù„Ø³Ø©)":
        return last_n_sessions_range(df_, 1)

    if option == "Ø¢Ø®Ø± Ø£Ø³Ø¨ÙˆØ¹ (5 Ø¬Ù„Ø³Ø§Øª)":
        return last_n_sessions_range(df_, 5)

    if option == "Ø¢Ø®Ø± 10 Ø¬Ù„Ø³Ø§Øª":
        return last_n_sessions_range(df_, 10)

    if option == "Ø¢Ø®Ø± Ø´Ù‡Ø± (â‰ˆ22 Ø¬Ù„Ø³Ø©)":
        return last_n_sessions_range(df_, 22)

    if option == "Ø¢Ø®Ø± 3 Ø´Ù‡ÙˆØ± (â‰ˆ66 Ø¬Ù„Ø³Ø©)":
        return last_n_sessions_range(df_, 66)

    if option == "Ù…Ù† Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„Ø³Ù†Ø© (YTD)":
        return ytd_range(df_)

    if option == "ÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª":
        return (min_date, max_date)

    return None, None


# =========================
# Top filters
# =========================
# =========================
# Top filters (Dropdown ranges + manual dates)
# =========================
# =========================
# Helpers for Quick Ranges (put once, before Top filters)
# =========================
def trading_dates(df_: pd.DataFrame):
    return sorted(df_["Ø§Ù„ØªØ§Ø±ÙŠØ®"].dropna().dt.date.unique().tolist())

def last_n_sessions_range(df_: pd.DataFrame, n: int):
    dates = trading_dates(df_)
    if not dates:
        return None, None
    n = max(1, int(n))
    tail = dates[-n:] if len(dates) >= n else dates
    return tail[0], tail[-1]

def ytd_range(df_: pd.DataFrame):
    dates = trading_dates(df_)
    if not dates:
        return None, None
    last_day = dates[-1]
    y0 = last_day.replace(month=1, day=1)
    start = next((d for d in dates if d >= y0), dates[0])
    return start, last_day

def apply_quick_range(df_: pd.DataFrame, option: str, min_date, max_date):
    if option == "Ù…Ø®ØµØµ":
        return None, None
    if option == "Ø¢Ø®Ø± ÙŠÙˆÙ… (Ø¢Ø®Ø± Ø¬Ù„Ø³Ø©)":
        return last_n_sessions_range(df_, 1)
    if option == "Ø¢Ø®Ø± Ø£Ø³Ø¨ÙˆØ¹ (5 Ø¬Ù„Ø³Ø§Øª)":
        return last_n_sessions_range(df_, 5)
    if option == "Ø¢Ø®Ø± 10 Ø¬Ù„Ø³Ø§Øª":
        return last_n_sessions_range(df_, 10)
    if option == "Ø¢Ø®Ø± Ø´Ù‡Ø± (â‰ˆ22 Ø¬Ù„Ø³Ø©)":
        return last_n_sessions_range(df_, 22)
    if option == "Ø¢Ø®Ø± 3 Ø´Ù‡ÙˆØ± (â‰ˆ66 Ø¬Ù„Ø³Ø©)":
        return last_n_sessions_range(df_, 66)
    if option == "Ù…Ù† Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„Ø³Ù†Ø© (YTD)":
        return ytd_range(df_)
    if option == "ÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª":
        return (min_date, max_date)
    return None, None


# =========================
# Top filters (CLEAN) - Dropdown quick range + manual dates + symbol
# =========================
min_d, max_d = df["Ø§Ù„ØªØ§Ø±ÙŠØ®"].min(), df["Ø§Ù„ØªØ§Ø±ÙŠØ®"].max()
min_date, max_date = min_d.date(), max_d.date()

QUICK_OPTIONS = [
    "Ù…Ø®ØµØµ",
    "Ø¢Ø®Ø± ÙŠÙˆÙ… (Ø¢Ø®Ø± Ø¬Ù„Ø³Ø©)",
    "Ø¢Ø®Ø± Ø£Ø³Ø¨ÙˆØ¹ (5 Ø¬Ù„Ø³Ø§Øª)",
    "Ø¢Ø®Ø± 10 Ø¬Ù„Ø³Ø§Øª",
    "Ø¢Ø®Ø± Ø´Ù‡Ø± (â‰ˆ22 Ø¬Ù„Ø³Ø©)",
    "Ø¢Ø®Ø± 3 Ø´Ù‡ÙˆØ± (â‰ˆ66 Ø¬Ù„Ø³Ø©)",
    "Ù…Ù† Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„Ø³Ù†Ø© (YTD)",
    "ÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª",
]

# --- init session state once ---
if "quick_range" not in st.session_state:
    st.session_state["quick_range"] = "Ù…Ø®ØµØµ"
if "start_date" not in st.session_state:
    st.session_state["start_date"] = min_date
if "end_date" not in st.session_state:
    st.session_state["end_date"] = max_date

# --- quick range row (mobile friendly) ---
# --- quick range row (aligned) ---
qr1, qr2 = st.columns([4, 1])

with qr1:
    st.selectbox(
        "â±ï¸ Ù†Ø·Ø§Ù‚ Ø²Ù…Ù†ÙŠ Ø³Ø±ÙŠØ¹",
        options=QUICK_OPTIONS,
        index=QUICK_OPTIONS.index(st.session_state["quick_range"]) if st.session_state["quick_range"] in QUICK_OPTIONS else 0,
        key="quick_range",
    )

with qr2:
    # Spacer ÙŠÙ†Ø²Ù„ Ø§Ù„Ø²Ø±Ø§Ø± Ù„Ù†ÙØ³ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù€ selectbox
    st.markdown("<div style='height: 28px'></div>", unsafe_allow_html=True)
    if st.button("ØªØ·Ø¨ÙŠÙ‚", use_container_width=True, key="apply_quick_btn"):
        s, e = apply_quick_range(df, st.session_state["quick_range"], min_date, max_date)
        if s and e:
            st.session_state["start_date"] = s
            st.session_state["end_date"] = e
        st.rerun()



# --- manual dates + symbol ---
c1, c2, c3 = st.columns([2, 2, 3])

with c1:
    st.date_input(
        "Ù…Ù† ØªØ§Ø±ÙŠØ®",
        min_value=min_date,
        max_value=max_date,
        key="start_date",
    )

with c2:
    st.date_input(
        "Ø¥Ù„Ù‰ ØªØ§Ø±ÙŠØ®",
        min_value=min_date,
        max_value=max_date,
        key="end_date",
    )

with c3:
    symbols = sorted(df["Ø§Ù„Ø±Ù…Ø²"].dropna().unique().tolist())
    selected_symbol = st.selectbox(
        "Ø§Ø®ØªØ± Ø³Ù‡Ù… Ù„Ù„ØªÙØ§ØµÙŠÙ„",
        options=["(Ø§Ù„Ø³ÙˆÙ‚)"] + symbols,
        key="selected_symbol",
    )

# --- keep dates valid & treat manual edits as "custom" ---
# (Ù„Ùˆ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ØºÙŠÙ‘Ø± ÙŠØ¯ÙˆÙŠØŒ Ù†Ø®Ù„ÙŠ Ø§Ù„Ù†Ø·Ø§Ù‚ "Ù…Ø®ØµØµ")
if st.session_state["start_date"] > st.session_state["end_date"]:
    st.session_state["start_date"], st.session_state["end_date"] = st.session_state["end_date"], st.session_state["start_date"]
    st.session_state["quick_range"] = "Ù…Ø®ØµØµ"
    st.rerun()

# Ù„Ùˆ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù„Ù…Ø³ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ® ÙŠØ¯ÙˆÙŠÙ‹Ø§ (ÙˆÙ…Ø´ Ù…ØªØ³Ù‚Ø© Ù…Ø¹ Ø§Ù„Ù†Ø·Ø§Ù‚ Ø§Ù„Ø³Ø±ÙŠØ¹)ØŒ Ø±Ø¬Ù‘Ø¹Ù‡Ø§ "Ù…Ø®ØµØµ"
# (Ù†ÙƒØªÙÙŠ Ø¨Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ù„Ù…Ø®ØµØµ Ø¯Ø§Ø¦Ù…Ù‹Ø§ Ø¹Ù†Ø¯ Ø£ÙŠ ØªØ¹Ø¯ÙŠÙ„ ÙŠØ¯ÙˆÙŠ)
# Ù…Ù„Ø§Ø­Ø¸Ø©: Streamlit Ù…Ø´ Ø¨ÙŠØ¯ÙŠÙ†Ø§ event Ù…Ø¨Ø§Ø´Ø±ØŒ ÙØ¯Ù‡ Ø³Ù„ÙˆÙƒ Ø¹Ù…Ù„ÙŠ ÙˆØ¨Ø³ÙŠØ·.
if st.session_state["quick_range"] != "Ù…Ø®ØµØµ":
    # Ù„Ùˆ Ø§Ø®ØªØ§Ø± Ù†Ø·Ø§Ù‚ Ø³Ø±ÙŠØ¹ Ù„ÙƒÙ† Ø¨Ø¹Ø¯ÙŠÙ† Ø¹Ø¯Ù‘Ù„ Ø§Ù„ØªØ§Ø±ÙŠØ® ÙŠØ¯ÙˆÙŠÙ‹Ø§ØŒ ØºØ§Ù„Ø¨Ù‹Ø§ Ø¯Ù‡ "Ù…Ø®ØµØµ"
    # Ø®Ù„Ù‘ÙŠÙ‡Ø§ Ù…Ø®ØµØµ ÙÙŠ Ø£ÙˆÙ„ rerun Ø¨Ø¹Ø¯ Ø£ÙŠ Ø§Ø®ØªÙ„Ø§Ù Ø¨Ø³ÙŠØ·
    # (Ø§Ø®ØªÙŠØ§Ø±ÙŠ Ù„ÙƒÙ†Ù‡ Ù…ÙÙŠØ¯)
    pass

start_date = st.session_state["start_date"]
end_date = st.session_state["end_date"]

base_dff = df[(df["Ø§Ù„ØªØ§Ø±ÙŠØ®"].dt.date >= start_date) & (df["Ø§Ù„ØªØ§Ø±ÙŠØ®"].dt.date <= end_date)].copy()



# =========================
# Tabs
# =========================
tab_market, tab_watch, tab_details, tab_history, tab_help, tab_about, tab_readme, tab_settings = st.tabs(
    ["ğŸ“ˆ Ø§Ù„Ø³ÙˆÙ‚", "ğŸ“Œ Ù…Ø±Ø§Ù‚Ø¨ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©", "ğŸ” ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø³Ù‡Ù…", "ğŸ“Š ØªØ§Ø±ÙŠØ® Ø§Ù„Ø³ÙŠÙˆÙ„Ø©", "â“ Help", "â„¹ï¸ About", "ğŸ“„ README", "âš™ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª"]
)

# =========================
# SETTINGS TAB
# =========================
with tab_settings:
    st.header("âš™ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¹Ø±Ø¶")

    mode = st.radio(
        "ÙˆØ¶Ø¹ Ø§Ù„Ø­Ø³Ø§Ø¨",
        ["ÙØªØ±Ø© Ù…Ø®ØµØµØ©", "Ø¢Ø®Ø± 10 Ø¬Ù„Ø³Ø§Øª", "Ø¢Ø®Ø± Ø¬Ù„Ø³Ø© ÙÙ‚Ø·"],
        horizontal=True,
        index=0,
        key="mode_calc"
    )

    net_filter = st.radio(
        "ÙÙ„ØªØ± Ø§ØªØ¬Ø§Ù‡ ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©",
        ["Ø§Ù„ÙƒÙ„", "ØµØ§ÙÙŠ Ù…ÙˆØ¬Ø¨ ÙÙ‚Ø·", "ØµØ§ÙÙŠ Ø³Ø§Ù„Ø¨ ÙÙ‚Ø·"],
        horizontal=True,
        index=0,
        key="net_filter"
    )

    min_liq_pct = st.slider(
        "ÙÙ„ØªØ± Ù†Ø³Ø¨Ø© Ù…Ø®Ø·Ø· Ø§Ù„Ø³ÙŠÙˆÙ„Ø© (â‰¥)",
        0, 100, 0, 5,
        key="min_liq_pct"
    )

    change_mode = st.selectbox(
        "Ø¹Ø±Ø¶ % Ø§Ù„ØªØºÙŠØ± ÙÙŠ Ø§Ù„Ù…Ù„Ø®Øµ",
        ["Ø¢Ø®Ø± Ø¬Ù„Ø³Ø©", "Ù…ØªÙˆØ³Ø·", "Ù…ØªÙˆØ³Ø· Ù…Ø±Ø¬Ù‘Ø­ (Ù‚ÙŠÙ…Ø© Ø§Ù„ØªØ¯Ø§ÙˆÙ„)"],
        index=1,
        key="change_mode"
    )

    st.caption("Ù…Ù„Ø§Ø­Ø¸Ø©: Ø§Ù„ØªØ§Ø¨Ø§Øª Ø§Ù„Ø£Ø®Ø±Ù‰ ØªØ³ØªØ®Ø¯Ù… Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø¯ÙŠ ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§.")

# =========================
# Apply settings
# =========================
dff = base_dff.copy()

if mode == "Ø¢Ø®Ø± 10 Ø¬Ù„Ø³Ø§Øª":
    last_dates = sorted(dff["Ø§Ù„ØªØ§Ø±ÙŠØ®"].dt.date.dropna().unique().tolist())
    last_dates = last_dates[-10:] if len(last_dates) > 10 else last_dates
    dff = dff[dff["Ø§Ù„ØªØ§Ø±ÙŠØ®"].dt.date.isin(last_dates)].copy()

elif mode == "Ø¢Ø®Ø± Ø¬Ù„Ø³Ø© ÙÙ‚Ø·":
    if not dff.empty:
        last_day = dff["Ø§Ù„ØªØ§Ø±ÙŠØ®"].max()
        dff = dff[dff["Ø§Ù„ØªØ§Ø±ÙŠØ®"] == last_day].copy()

if "Ù†Ø³Ø¨Ø© Ù…Ø®Ø·Ø· Ø§Ù„Ø³ÙŠÙˆÙ„Ø©" in dff.columns and min_liq_pct > 0:
    dff = dff[dff["Ù†Ø³Ø¨Ø© Ù…Ø®Ø·Ø· Ø§Ù„Ø³ÙŠÙˆÙ„Ø©"] >= min_liq_pct].copy()

if net_filter == "ØµØ§ÙÙŠ Ù…ÙˆØ¬Ø¨ ÙÙ‚Ø·":
    dff = dff[dff["ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©"] > 0].copy()
elif net_filter == "ØµØ§ÙÙŠ Ø³Ø§Ù„Ø¨ ÙÙ‚Ø·":
    dff = dff[dff["ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©"] < 0].copy()

# Ù†Ø·Ø§Ù‚ Ø§Ù„Ø¹Ø±Ø¶ (Ø³ÙˆÙ‚ Ø£Ùˆ Ø³Ù‡Ù…)
if selected_symbol != "(Ø§Ù„Ø³ÙˆÙ‚)":
    scope_df = dff[dff["Ø§Ù„Ø±Ù…Ø²"] == selected_symbol].copy()
    nm = scope_df["Ø§Ø³Ù…_Ù†Ù‡Ø§Ø¦ÙŠ"].iloc[0] if (not scope_df.empty and "Ø§Ø³Ù…_Ù†Ù‡Ø§Ø¦ÙŠ" in scope_df.columns) else ""
    scope_label = f"{selected_symbol} - {nm}".strip(" -")
else:
    scope_df = dff
    scope_label = "Ø§Ù„Ø³ÙˆÙ‚"

# Key base (ÙŠÙ…Ù†Ø¹ Duplicate IDs)
key_base = f"{selected_symbol}_{start_date}_{end_date}_{mode}_{net_filter}_{min_liq_pct}"

# =========================
# TAB: Help
# =========================
with tab_help:
    st.header("â“ Help")
    st.markdown(
        """
### Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
- **Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„ÙØªØ±Ø©**: Ù…Ù† Ø£Ø¹Ù„Ù‰ Ø§Ù„ØµÙØ­Ø© (Ù…Ù†/Ø¥Ù„Ù‰).
- **Ø§Ø®ØªÙŠØ§Ø± Ø³Ù‡Ù…**: Ù…Ù† Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£Ø³Ù‡Ù… Ù„Ø¹Ø±Ø¶ ØªÙØ§ØµÙŠÙ„Ù‡.
- **Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª**: Ù…Ù† Tab (âš™ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª) Ù„ØªØ­Ø¯ÙŠØ¯:
  - ÙØªØ±Ø© Ù…Ø®ØµØµØ© / Ø¢Ø®Ø± 10 Ø¬Ù„Ø³Ø§Øª / Ø¢Ø®Ø± Ø¬Ù„Ø³Ø© ÙÙ‚Ø·
  - ÙÙ„ØªØ±Ø© ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø© (Ù…ÙˆØ¬Ø¨ ÙÙ‚Ø· / Ø³Ø§Ù„Ø¨ ÙÙ‚Ø·)
  - ÙÙ„ØªØ±Ø© Ù†Ø³Ø¨Ø© Ù…Ø®Ø·Ø· Ø§Ù„Ø³ÙŠÙˆÙ„Ø©

### Ù…Ù„Ø§Ø­Ø¸Ø§Øª
- ØªÙ… Ø¥Ø¶Ø§ÙØ© ØªØµØ­ÙŠØ­ ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù„Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© (OCR cleanup) + Ù‚Ø§Ù…ÙˆØ³ Ø±Ù…ÙˆØ² (Overrides).
- Ø§Ù„Ø£Ù„ÙˆØ§Ù†: **Ø£Ø®Ø¶Ø± = ØµØ§ÙÙŠ Ù…ÙˆØ¬Ø¨**ØŒ **Ø£Ø­Ù…Ø± = ØµØ§ÙÙŠ Ø³Ø§Ù„Ø¨**.
"""
    )
    st.info(DISCLAIMER)

# =========================
# TAB: About
# =========================
with tab_about:
    st.header("â„¹ï¸ About")
    st.markdown(
        f"""
**{APP_TITLE}** â€” *{APP_SUBTITLE}*  
Version: `{APP_VERSION}`

**Owner / Author:** {AUTHOR}  
**Copyright:** {COPYRIGHT}

### Intellectual Property
- Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ù…Ø³Ù…ÙˆØ­ Ø¹Ø¨Ø± Ø§Ù„Ø±Ø§Ø¨Ø· ÙÙ‚Ø·.
- ÙŠÙ…Ù†Ø¹ Ù†Ø³Ø®/ØªØ¹Ø¯ÙŠÙ„/Ø¥Ø¹Ø§Ø¯Ø© ØªÙˆØ²ÙŠØ¹ Ø§Ù„ÙƒÙˆØ¯ Ø£Ùˆ Ø£ÙŠ Ø¬Ø²Ø¡ Ù…Ù†Ù‡ Ø¨Ø¯ÙˆÙ† Ø¥Ø°Ù† ÙƒØªØ§Ø¨ÙŠ Ù…Ù† Ø§Ù„Ù…Ø§Ù„Ùƒ.

### Contact
- Email: [{EMAIL}](mailto:{EMAIL})
- WhatsApp: {WHATSAPP_URL}
- Telegram: {TELEGRAM_URL}

**Disclaimer:** {DISCLAIMER}
"""
    )

# =========================
# TAB: README
# =========================
with tab_readme:
    st.header("ğŸ“„ README Ø¯Ø§Ø®Ù„ Ø§Ù„Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯")
    if README_PATH.exists():
        readme_text = README_PATH.read_text(encoding="utf-8")
        st.download_button(
            "â¬‡ï¸ ØªØ­Ù…ÙŠÙ„ README.md",
            data=readme_text,
            file_name="README.md",
            mime="text/markdown",
            key="download_readme"
        )
        st.markdown(readme_text)
    else:
        st.warning("Ø§Ù„Ù…Ù„Ù README.md ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø¬Ø§Ù†Ø¨ app.py.")
        st.code(str(README_PATH))

# =========================
# TAB 1: Market summary
# =========================
with tab_market:
    st.header(f"Ù…Ù„Ø®Øµ ({scope_label})")

    if scope_df.empty:
        st.warning("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ø³Ø¨ Ø§Ù„ÙÙ„Ø§ØªØ± Ø§Ù„Ù…Ø®ØªØ§Ø±Ø©.")
    else:
        total_in = scope_df["Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ø§Ù„Ø¯Ø§Ø®Ù„Ø©"].sum()
        total_out = scope_df["Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ø§Ù„Ø®Ø§Ø±Ø¬Ø©"].sum()
        net = scope_df["ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©"].sum()
        change_value, change_delta = get_change_metric(scope_df, change_mode)

        m1, m2, m3, m4 = st.columns(4)
        m1.metric("Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ø§Ù„Ø¯Ø§Ø®Ù„Ø©", fmt_money(total_in))
        m2.metric("Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ø§Ù„Ø®Ø§Ø±Ø¬Ø©", fmt_money(total_out))
        m3.metric("ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©", fmt_money(net))
        m4.metric("% Ø§Ù„ØªØºÙŠØ±", change_value, delta=change_delta)

        pie_df = pd.DataFrame({"Ø§Ù„Ù†ÙˆØ¹": ["Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ø§Ù„Ø¯Ø§Ø®Ù„Ø©", "Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ø§Ù„Ø®Ø§Ø±Ø¬Ø©"], "Ø§Ù„Ù‚ÙŠÙ…Ø©": [total_in, total_out]})
        fig_pie = px.pie(pie_df, names="Ø§Ù„Ù†ÙˆØ¹", values="Ø§Ù„Ù‚ÙŠÙ…Ø©", hole=0.6)
        fig_pie.update_traces(
            textposition="outside",
            textinfo="percent+label",
            marker=dict(colors=[GREEN, RED])
        )
        fig_pie = add_watermark(fig_pie)

        daily_net = (
            scope_df.assign(Ø§Ù„ØªØ§Ø±ÙŠØ®=scope_df["Ø§Ù„ØªØ§Ø±ÙŠØ®"].dt.date)
                    .groupby("Ø§Ù„ØªØ§Ø±ÙŠØ®", as_index=False)["ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©"].sum()
        )
        daily_net["Ø§Ù„Ø¥Ø´Ø§Ø±Ø©"] = daily_net["ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©"].apply(lambda x: "Ù…ÙˆØ¬Ø¨" if x >= 0 else "Ø³Ø§Ù„Ø¨")

        fig_market = px.bar(
            daily_net, x="Ø§Ù„ØªØ§Ø±ÙŠØ®", y="ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©",
            color="Ø§Ù„Ø¥Ø´Ø§Ø±Ø©",
            color_discrete_map=SIGN_COLOR_MAP,
        )
        fig_market.update_layout(legend_title_text="")
        fig_market = add_watermark(fig_market)

        left, right = st.columns([1, 1])
        with left:
            st.plotly_chart(fig_pie, use_container_width=True, key=f"pie_{key_base}")
        with right:
            st.plotly_chart(fig_market, use_container_width=True, key=f"market_{key_base}")

# =========================
# TAB 2: Watchlist
# =========================
with tab_watch:
    st.header("Ù…Ø±Ø§Ù‚Ø¨ Ø§Ù„Ø³ÙŠÙˆÙ„Ø© (ØªØ±ØªÙŠØ¨ Ø§Ù„Ø£Ø³Ù‡Ù…)")

    if dff.empty:
        st.warning("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ø³Ø¨ Ø§Ù„ÙÙ„Ø§ØªØ± Ø§Ù„Ù…Ø®ØªØ§Ø±Ø©.")
    else:
        def most_common_name(x):
            x = x.dropna().astype(str).str.strip()
            if x.empty:
                return ""
            return x.value_counts().idxmax()

        agg_map = {"Ø§Ø³Ù…_Ù†Ù‡Ø§Ø¦ÙŠ": most_common_name, "ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©": "sum"}
        if "Ù‚ÙŠÙ…Ø© Ø§Ù„ØªØ¯Ø§ÙˆÙ„" in dff.columns:
            agg_map["Ù‚ÙŠÙ…Ø© Ø§Ù„ØªØ¯Ø§ÙˆÙ„"] = "sum"
        if "Ø§Ù„ØªØºÙŠØ± %" in dff.columns:
            agg_map["Ø§Ù„ØªØºÙŠØ± %"] = "mean"

        rank = dff.groupby("Ø§Ù„Ø±Ù…Ø²", as_index=False).agg(agg_map)

        consec_map = {sym: consecutive_positive_days(dff[dff["Ø§Ù„Ø±Ù…Ø²"] == sym]) for sym in rank["Ø§Ù„Ø±Ù…Ø²"].tolist()}
        rank["Ø£ÙŠØ§Ù… Ù…ØªØªØ§Ù„ÙŠØ© (ØµØ§ÙÙŠ Ù…ÙˆØ¬Ø¨)"] = rank["Ø§Ù„Ø±Ù…Ø²"].map(consec_map).fillna(0).astype(int)

        rank = rank.sort_values("ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©", ascending=False)

        top_n = st.slider("Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø³Ù‡Ù… Ø§Ù„Ù…Ø¹Ø±ÙˆØ¶Ø©", 10, 200, 30, 10, key="topn_watch")
        show_raw = rank.head(top_n).copy().rename(columns={"Ø§Ø³Ù…_Ù†Ù‡Ø§Ø¦ÙŠ": "Ø§Ù„Ø¥Ø³Ù…"})

        styler = show_raw.style.applymap(style_net_column, subset=["ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©"])
        fmt_map = {"ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©": lambda v: fmt_money(v)}
        if "Ù‚ÙŠÙ…Ø© Ø§Ù„ØªØ¯Ø§ÙˆÙ„" in show_raw.columns:
            fmt_map["Ù‚ÙŠÙ…Ø© Ø§Ù„ØªØ¯Ø§ÙˆÙ„"] = lambda v: fmt_money(v)
        if "Ø§Ù„ØªØºÙŠØ± %" in show_raw.columns:
            fmt_map["Ø§Ù„ØªØºÙŠØ± %"] = "{:.2f}".format
        styler = styler.format(fmt_map)

        st.dataframe(styler, use_container_width=True, hide_index=True, key=f"watch_{key_base}")

# =========================
# TAB 3: Details
# =========================
with tab_details:
    st.header("ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø³Ù‡Ù…")

    if selected_symbol == "(Ø§Ù„Ø³ÙˆÙ‚)":
        st.info("Ø§Ø®ØªØ± Ø³Ù‡Ù… Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„Ø£Ø¹Ù„Ù‰ Ù„Ø¹Ø±Ø¶ Ø§Ù„ØªÙØ§ØµÙŠÙ„.")
    elif scope_df.empty:
        st.warning("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø³Ù‡Ù… Ø­Ø³Ø¨ Ø§Ù„ÙÙ„Ø§ØªØ± Ø§Ù„Ù…Ø®ØªØ§Ø±Ø©.")
    else:
        sym_df = scope_df.copy().sort_values("Ø§Ù„ØªØ§Ø±ÙŠØ®")

        c1, c2 = st.columns([2, 1])
        with c1:
            sym_daily = (
                sym_df.assign(Ø§Ù„ØªØ§Ø±ÙŠØ®=sym_df["Ø§Ù„ØªØ§Ø±ÙŠØ®"].dt.date)
                      .groupby("Ø§Ù„ØªØ§Ø±ÙŠØ®", as_index=False)["ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©"].sum()
            )
            sym_daily["Ø§Ù„Ø¥Ø´Ø§Ø±Ø©"] = sym_daily["ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©"].apply(lambda x: "Ù…ÙˆØ¬Ø¨" if x >= 0 else "Ø³Ø§Ù„Ø¨")

            fig_sym = px.bar(
                sym_daily,
                x="Ø§Ù„ØªØ§Ø±ÙŠØ®",
                y="ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©",
                color="Ø§Ù„Ø¥Ø´Ø§Ø±Ø©",
                color_discrete_map=SIGN_COLOR_MAP,
            )
            fig_sym.update_layout(legend_title_text="")
            fig_sym = add_watermark(fig_sym)

            st.plotly_chart(fig_sym, use_container_width=True, key=f"sym_{key_base}")

        with c2:
            st.write("**Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ÙØªØ±Ø©**")
            st.metric("Ø§Ù„Ø¥Ø³Ù…", sym_df["Ø§Ø³Ù…_Ù†Ù‡Ø§Ø¦ÙŠ"].iloc[0] if "Ø§Ø³Ù…_Ù†Ù‡Ø§Ø¦ÙŠ" in sym_df.columns else "-")
            st.metric("ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©", fmt_money(sym_df["ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©"].sum()))
            if "Ø§Ù„ØªØºÙŠØ± %" in sym_df.columns:
                st.metric("Ù…ØªÙˆØ³Ø· Ø§Ù„ØªØºÙŠØ± %", f'{sym_df["Ø§Ù„ØªØºÙŠØ± %"].mean():.2f}%')
            if "Ø¢Ø®Ø± Ø³Ø¹Ø±" in sym_df.columns and not sym_df.empty and not pd.isna(sym_df.iloc[-1].get("Ø¢Ø®Ø± Ø³Ø¹Ø±")):
                st.metric("Ø¢Ø®Ø± Ø³Ø¹Ø± (Ø¢Ø®Ø± Ø¬Ù„Ø³Ø©)", f'{float(sym_df.iloc[-1]["Ø¢Ø®Ø± Ø³Ø¹Ø±"]):.2f}')
            st.metric("Ø£ÙŠØ§Ù… Ù…ØªØªØ§Ù„ÙŠØ© ØµØ§ÙÙŠ Ù…ÙˆØ¬Ø¨", str(consecutive_positive_days(sym_df)))

        st.write("**ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø¬Ù„Ø³Ø§Øª**")
        view_cols = [
            "Ø§Ù„ØªØ§Ø±ÙŠØ®", "Ø§Ù„Ø±Ù…Ø²", "Ø§Ø³Ù…_Ù†Ù‡Ø§Ø¦ÙŠ",
            "Ø¢Ø®Ø± Ø³Ø¹Ø±", "Ø§Ù„ØªØºÙŠØ± %",
            "Ù‚ÙŠÙ…Ø© Ø§Ù„ØªØ¯Ø§ÙˆÙ„", "Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ø§Ù„Ø¯Ø§Ø®Ù„Ø©", "Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ø§Ù„Ø®Ø§Ø±Ø¬Ø©",
            "ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©", "Ù†Ø³Ø¨Ø© Ù…Ø®Ø·Ø· Ø§Ù„Ø³ÙŠÙˆÙ„Ø©",
            "Ø§Ù„Ù…ØµØ¯Ø±"
        ]
        view_cols = [c for c in view_cols if c in sym_df.columns]
        show_table = sym_df[view_cols].rename(columns={"Ø§Ø³Ù…_Ù†Ù‡Ø§Ø¦ÙŠ": "Ø§Ù„Ø¥Ø³Ù…"})
        st.dataframe(
            show_table.sort_values("Ø§Ù„ØªØ§Ø±ÙŠØ®", ascending=False),
            use_container_width=True,
            hide_index=True,
            key=f"details_tbl_{key_base}"
        )

# =========================
# TAB 4: History
# =========================
with tab_history:
    st.header(f"ØªØ§Ø±ÙŠØ® Ø§Ù„Ø³ÙŠÙˆÙ„Ø© ({scope_label})")

    if scope_df.empty:
        st.warning("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ø³Ø¨ Ø§Ù„ÙÙ„Ø§ØªØ± Ø§Ù„Ù…Ø®ØªØ§Ø±Ø©.")
    else:
        agg_map = {
            "ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©": "sum",
            "Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ø§Ù„Ø¯Ø§Ø®Ù„Ø©": "sum",
            "Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ø§Ù„Ø®Ø§Ø±Ø¬Ø©": "sum",
        }
        if "Ø§Ù„ØªØºÙŠØ± %" in scope_df.columns:
            agg_map["Ø§Ù„ØªØºÙŠØ± %"] = "mean"
        if "Ø¢Ø®Ø± Ø³Ø¹Ø±" in scope_df.columns:
            agg_map["Ø¢Ø®Ø± Ø³Ø¹Ø±"] = "last"

        hist = (
            scope_df.assign(Ø§Ù„ØªØ§Ø±ÙŠØ®=scope_df["Ø§Ù„ØªØ§Ø±ÙŠØ®"].dt.date)
                    .groupby("Ø§Ù„ØªØ§Ø±ÙŠØ®", as_index=False)
                    .agg(agg_map)
        ).sort_values("Ø§Ù„ØªØ§Ø±ÙŠØ®")

        hist["Ø§Ù„Ø¥Ø´Ø§Ø±Ø©"] = hist["ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©"].apply(lambda x: "Ù…ÙˆØ¬Ø¨" if x >= 0 else "Ø³Ø§Ù„Ø¨")

        fig_hist = px.bar(
            hist, x="Ø§Ù„ØªØ§Ø±ÙŠØ®", y="ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©",
            color="Ø§Ù„Ø¥Ø´Ø§Ø±Ø©",
            color_discrete_map=SIGN_COLOR_MAP,
        )
        fig_hist.update_layout(legend_title_text="")
        fig_hist = add_watermark(fig_hist)

        st.plotly_chart(fig_hist, use_container_width=True, key=f"hist_{key_base}")

        table_cols = ["Ø§Ù„ØªØ§Ø±ÙŠØ®", "Ø¢Ø®Ø± Ø³Ø¹Ø±", "Ø§Ù„ØªØºÙŠØ± %", "ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©", "Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ø§Ù„Ø¯Ø§Ø®Ù„Ø©", "Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ø§Ù„Ø®Ø§Ø±Ø¬Ø©"]
        table_cols = [c for c in table_cols if c in hist.columns]
        hist_show = hist[table_cols].copy()

        if "Ø§Ù„ØªØºÙŠØ± %" in hist_show.columns:
            hist_show["Ø§Ù„ØªØºÙŠØ± %"] = hist_show["Ø§Ù„ØªØºÙŠØ± %"].round(2)

        for c in ["ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©", "Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ø§Ù„Ø¯Ø§Ø®Ù„Ø©", "Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ø§Ù„Ø®Ø§Ø±Ø¬Ø©"]:
            if c in hist_show.columns:
                hist_show[c] = hist_show[c].apply(fmt_money)

        st.dataframe(
            hist_show.sort_values("Ø§Ù„ØªØ§Ø±ÙŠØ®", ascending=False),
            use_container_width=True,
            hide_index=True,
            key=f"hist_tbl_{key_base}"
        )

# =========================
# Footer
# =========================
st.markdown(
    f"""
    <hr>
    <div style='text-align:center; opacity:0.85; font-weight:700;'>
        {COPYRIGHT} â€” {DISCLAIMER}<br>
        Contact: <a href="mailto:{EMAIL}">{EMAIL}</a> |
        <a href="{WHATSAPP_URL}" target="_blank">WhatsApp</a> |
        <a href="{TELEGRAM_URL}" target="_blank">Telegram</a>
    </div>
    """,
    unsafe_allow_html=True
)
