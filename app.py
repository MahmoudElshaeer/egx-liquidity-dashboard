import re
import pandas as pd
import streamlit as st
import plotly.express as px
from pathlib import Path

# =========================
# App Meta (Ø­Ù‚ÙˆÙ‚ + About)
# =========================
APP_TITLE = "Ù…Ø±Ø§Ù‚Ø¨ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©"
APP_SUBTITLE = "EGX Liquidity Monitor Dashboard"
APP_VERSION = "1.1.0"
AUTHOR = "Mahmoud Abdrabbo"
COPYRIGHT = f"Â© 2026 {AUTHOR}. All rights reserved."
DISCLAIMER = "Ù‡Ø°Ø§ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ù„Ø£ØºØ±Ø§Ø¶ Ù…Ø¹Ù„ÙˆÙ…Ø§ØªÙŠØ© ÙÙ‚Ø· ÙˆÙ„Ø§ ÙŠÙØ¹Ø¯ ØªÙˆØµÙŠØ© Ø§Ø³ØªØ«Ù…Ø§Ø±ÙŠØ©."

WHATSAPP_URL = "https://wa.me/qr/37OH2UF3VH7PM1"
TELEGRAM_URL = "https://t.me/Mahmoud_abdrabbo"
EMAIL = "mahmoud_elshaeer@yahoo.com"

st.set_page_config(page_title=APP_TITLE, layout="wide")

PROJECT_DIR = Path(__file__).resolve().parent
README_PATH = PROJECT_DIR / "README.md"

# Ù„Ù„Ù€ Cloud: Ø®Ù„ÙŠ Ø§Ù„Ù…Ù„Ù ÙÙŠ Ù†ÙØ³ Ø§Ù„Ø±ÙŠØ¨Ùˆ Ø¨Ø§Ø³Ù… liquidity_all.xlsx
#DATA_PATH = PROJECT_DIR / "liquidity_all.xlsx"
DATA_PATH = Path(__file__).resolve().parent / "liquidity_all.xlsx"

# =========================
# CSS (ØªÙƒØ¨ÙŠØ± Ø§Ù„ØªØ§Ø¨Ø§Øª + Ø¹Ù†Ø§ÙˆÙŠÙ†)
# =========================
st.markdown(
    """
    <style>
    /* ØªÙƒØ¨ÙŠØ± Ø®Ø· Ø§Ù„ØªØ§Ø¨Ø§Øª */
    div[data-baseweb="tab"] > button {
        font-size: 26px !important;
        font-weight: 800 !important;
        padding-top: 12px !important;
        padding-bottom: 12px !important;
    }
    /* ØªÙƒØ¨ÙŠØ± Ø¹Ù†ÙˆØ§Ù† Ø§Ù„ØµÙØ­Ø© */
    h1 { font-size: 42px !important; }
    /* ØªÙƒØ¨ÙŠØ± Ø¹Ù†Ø§ÙˆÙŠÙ† Ø§Ù„Ø£Ù‚Ø³Ø§Ù… */
    h2 { font-size: 32px !important; }
    h3 { font-size: 26px !important; }
    </style>
    """,
    unsafe_allow_html=True
)

# =========================
# Ø§Ø³Ù…Ø§Ø¡ Ù…ØµØ­Ø­Ø© Ø­Ø³Ø¨ Ø§Ù„Ø±Ù…Ø² (Overrides)
# =========================
NAME_OVERRIDES = {
    "COMI": "Ø§Ù„Ø¨Ù†Ùƒ Ø§Ù„ØªØ¬Ø§Ø±ÙŠ Ø§Ù„Ø¯ÙˆÙ„ÙŠ",
    "HDBK": "Ø¨Ù†Ùƒ Ø§Ù„ØªØ¹Ù…ÙŠØ± ÙˆØ§Ù„Ø¥Ø³ÙƒØ§Ù†",
    "ADIB": "Ù…ØµØ±Ù Ø£Ø¨ÙˆØ¸Ø¨ÙŠ Ø§Ù„Ø¥Ø³Ù„Ø§Ù…ÙŠ",
    "CCAP": "Ø§Ù„Ù‚Ù„Ø¹Ø©",
    "CLHO": "Ù…Ø³ØªØ´ÙÙ‰ ÙƒÙ„ÙŠÙˆØ¨Ø§ØªØ±Ø§",
    "EAST": "Ø¥ÙŠØ³ØªØ±Ù† ÙƒÙˆÙ…Ø¨Ø§Ù†ÙŠ",
    "FWRY": "ÙÙˆØ±ÙŠ",
    "BTFH": "Ø¨Ù„ØªÙˆÙ† Ø§Ù„Ù‚Ø§Ø¨Ø¶Ø©",
    "ACAMD": "Ø§Ù„Ø´Ø±ÙƒØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù„Ø¥Ø¯Ø§Ø±Ø© ÙˆØªØ·ÙˆÙŠØ± Ø§Ù„Ø£ØµÙˆÙ„",
    "ABUK": "Ø£Ø¨ÙˆÙ‚ÙŠØ± Ù„Ù„Ø£Ø³Ù…Ø¯Ø©",
    "TAQA": "Ø·Ø§Ù‚Ø© Ø¹Ø±Ø¨ÙŠØ©",
    "TMGH": "Ø·Ù„Ø¹Øª Ù…ØµØ·ÙÙ‰",
    "HRHO": "Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¥ÙŠ Ø¥Ù Ø¬ÙŠ Ø§Ù„Ù‚Ø§Ø¨Ø¶Ø©",
    "HELI": "Ù…ØµØ± Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ù„Ù„Ø¥Ø³ÙƒØ§Ù†",
    "ETRS": "Ø¥ÙŠØ¬ÙŠØªØ±Ø§Ù†Ø³",
    "ZEOT": "Ø§Ù„Ø²ÙŠÙˆØª Ø§Ù„Ù…Ø³ØªØ®Ù„ØµØ©",
    "ORAS": "Ø£ÙˆØ±Ø§Ø³ÙƒÙˆÙ… Ù„Ù„Ø¥Ù†Ø´Ø§Ø¡",
    "EGAL": "Ù…ØµØ± Ù„Ù„Ø£Ù„ÙˆÙ…Ù†ÙŠÙˆÙ…",
    "CRST": "ÙƒØ±Ø³ØªÙ…Ø§Ø±Ùƒ Ù„Ù„Ù…Ù‚Ø§ÙˆÙ„Ø§Øª",
    "OIH": "Ø£ÙˆØ±Ø§Ø³ÙƒÙˆÙ… Ù„Ù„Ø§Ø³ØªØ«Ù…Ø§Ø± Ø§Ù„Ù‚Ø§Ø¨Ø¶Ø©",
    "MFPC": "Ù…ÙˆØ¨ÙƒÙˆ",
    "ISMQ": "Ø§Ù„Ø­Ø¯ÙŠØ¯ ÙˆØ§Ù„ØµÙ„Ø¨ Ù„Ù„Ù…Ù†Ø§Ø¬Ù… ÙˆØ§Ù„Ù…Ø­Ø§Ø¬Ø±",
    "EGCH": "ÙƒÙŠÙ…Ø§",
    "NCCW": "Ø§Ù„Ù†ØµØ± Ù„Ù„Ø£Ø¹Ù…Ø§Ù„ Ø§Ù„Ù…Ø¯Ù†ÙŠØ©",
    "AMER": "Ø¹Ø§Ù…Ø± Ø¬Ø±ÙˆØ¨",
    "PHGC": "Ø¨Ø±ÙŠÙ…ÙŠÙ… Ù‡ÙŠÙ„Ø«ÙƒÙŠØ± Ø¬Ø±ÙˆØ¨",
    "PHDC": "Ø¨Ø§Ù„Ù… Ù‡ÙŠÙ„Ø²",
    "RAYA": "Ø±Ø§ÙŠØ©",
    # Ø¥Ø¶Ø§ÙØ§Øª Ù…Ù† Ù‚Ø§Ø¦Ù…ØªÙƒ:
    "ARAB": "Ø§Ù„Ù…Ø·ÙˆØ±ÙˆÙ† Ø§Ù„Ø¹Ø±Ø¨ Ø§Ù„Ù‚Ø§Ø¨Ø¶Ø©",
}

# =========================
# ØªÙ†Ø¸ÙŠÙ/ØªØ·Ø¨ÙŠØ¹ Ø¹Ø±Ø¨ÙŠ (General cleanup)
# =========================
ARABIC_TATWEEL = "\u0640"
ARABIC_DIACRITICS_RE = re.compile(r"[\u0617-\u061A\u064B-\u0652]")

def is_arabic_char(ch: str) -> bool:
    return "\u0600" <= ch <= "\u06FF"

def normalize_arabic_name(s: str) -> str:
    if s is None or (isinstance(s, float) and pd.isna(s)):
        return ""

    s = str(s)

    # Ø¥Ø²Ø§Ù„Ø© Ø§ØªØ¬Ø§Ù‡/Ø±Ù…ÙˆØ² Ø®ÙÙŠØ©
    s = (s.replace("\u200f", "")
           .replace("\u200e", "")
           .replace("\u202b", "")
           .replace("\u202a", "")
           .replace("\xa0", " ")
           .replace(ARABIC_TATWEEL, "")
        )

    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªØ´ÙƒÙŠÙ„
    s = ARABIC_DIACRITICS_RE.sub("", s)

    # ØªÙˆØ­ÙŠØ¯ Ù…Ø³Ø§ÙØ§Øª
    s = re.sub(r"\s+", " ", s).strip()

    # Ø¯Ù…Ø¬ Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ù„ÙŠ Ø§Ù„Ù€ OCR ÙØµÙ„Ù‡Ø§: "ÙƒÙˆÙ…Ø¨Ø§Ù† ÙŠ" -> "ÙƒÙˆÙ…Ø¨Ø§Ù†ÙŠ" / "Ø³ÙŠ Ø£ÙŠ Ø¨  ÙŠ" -> "Ø³ÙŠ Ø£ÙŠ Ø¨ÙŠ"
    tokens = s.split(" ")
    merged = []
    for tok in tokens:
        if len(tok) == 1 and merged and is_arabic_char(tok) and all(is_arabic_char(c) for c in merged[-1][-1:]):
            merged[-1] = merged[-1] + tok
        else:
            merged.append(tok)
    s = " ".join(merged)

    # Ø¥ØµÙ„Ø§Ø­Ø§Øª OCR Ø´Ø§Ø¦Ø¹Ø©
    fixes = [
        ("Ù…Ø±ØµÙ", "Ù…ØµØ±Ù"),
        ("Ù…Ø±Øµ", "Ù…ØµØ±"),
        ("Ù…Ø³ØªØ´Ù", "Ù…Ø³ØªØ´ÙÙ‰"),
        ("ÙˆØ§Ø¥", "ÙˆØ§Ù„Ø¥"),
        ("Ø§Ø¥", "Ø§Ù„Ø¥"),
        ("Ø§Ø§Ù„", "Ø§Ù„"),  # Ø§Ø§Ù„ØµÙˆÙ„ -> Ø§Ù„Ø§ØµÙˆÙ„ (ØªÙ‚Ø±ÙŠØ¨)
        ("Ø§ÙŠØ³Øª  Ù†", "Ø§ÙŠØ³ØªØ±Ù†"),
        ("ÙƒÙˆÙ…Ø¨Ø§Ø¦Ù†ÙŠ", "ÙƒÙˆÙ…Ø¨Ø§Ù†ÙŠ"),
        ("ÙƒÙˆÙ…Ø¨Ø§Ù† ÙŠ", "ÙƒÙˆÙ…Ø¨Ø§Ù†ÙŠ"),
    ]
    for a, b in fixes:
        s = s.replace(a, b)

    return s.strip()

# =========================
# Load + unify columns
# =========================
@st.cache_data
def load_data_df(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = df.columns.astype(str).str.strip()

    df = df.rename(columns={
        "ØµØ§ÙÙ‰ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©": "ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©",
        "Ø£Ø®Ø± Ø³Ø¹Ø±": "Ø¢Ø®Ø± Ø³Ø¹Ø±",
        "% Ù…Ø®Ø·Ø· Ø§Ù„Ø³ÙŠÙˆÙ„Ø©": "Ù†Ø³Ø¨Ø© Ù…Ø®Ø·Ø· Ø§Ù„Ø³ÙŠÙˆÙ„Ø©",
        "Ø§Ù„ØªØºÙŠØ±%": "Ø§Ù„ØªØºÙŠØ± %",
        "Ø§Ù„ØªØºÙŠØ± % ": "Ø§Ù„ØªØºÙŠØ± %",
        "Ø§Ù„Ø§Ø³Ù…": "Ø§Ù„Ø¥Ø³Ù…",
    })

    required = ["Ø§Ù„ØªØ§Ø±ÙŠØ®", "Ø§Ù„Ø±Ù…Ø²", "Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ø§Ù„Ø¯Ø§Ø®Ù„Ø©", "Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ø§Ù„Ø®Ø§Ø±Ø¬Ø©", "ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©"]
    missing = [c for c in required if c not in df.columns]
    if missing:
        raise ValueError(f"Ø£Ø¹Ù…Ø¯Ø© Ù†Ø§Ù‚ØµØ© ÙÙŠ Ø§Ù„Ù…Ù„Ù: {missing}")

    df["Ø§Ù„ØªØ§Ø±ÙŠØ®"] = pd.to_datetime(df["Ø§Ù„ØªØ§Ø±ÙŠØ®"], errors="coerce")

    # ØªØ­ÙˆÙŠÙ„ Ø£Ø±Ù‚Ø§Ù…
    num_cols = [
        "Ø¢Ø®Ø± Ø³Ø¹Ø±", "Ø§Ù„ØªØºÙŠØ± %", "Ù‚ÙŠÙ…Ø© Ø§Ù„ØªØ¯Ø§ÙˆÙ„",
        "Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ø§Ù„Ø¯Ø§Ø®Ù„Ø©", "Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ø§Ù„Ø®Ø§Ø±Ø¬Ø©", "ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©",
        "Ù†Ø³Ø¨Ø© Ù…Ø®Ø·Ø· Ø§Ù„Ø³ÙŠÙˆÙ„Ø©", "Ø±Ù‚Ù… Ø§Ù„ØµÙØ­Ø©"
    ]
    for c in num_cols:
        if c in df.columns:
            df[c] = df[c].astype(str).str.replace(",", "", regex=False).str.strip()
            df[c] = pd.to_numeric(df[c], errors="coerce")

    df = df.dropna(subset=["Ø§Ù„ØªØ§Ø±ÙŠØ®", "Ø§Ù„Ø±Ù…Ø²"]).copy()

    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© + Overrides
    if "Ø§Ù„Ø¥Ø³Ù…" in df.columns:
        df["Ø§Ø³Ù…_Ù…Ù†Ø¸Ù"] = df["Ø§Ù„Ø¥Ø³Ù…"].apply(normalize_arabic_name)
    else:
        df["Ø§Ø³Ù…_Ù…Ù†Ø¸Ù"] = ""

    df["Ø§Ø³Ù…_Ù†Ù‡Ø§Ø¦ÙŠ"] = df.apply(
        lambda r: NAME_OVERRIDES.get(str(r["Ø§Ù„Ø±Ù…Ø²"]).strip(), r["Ø§Ø³Ù…_Ù…Ù†Ø¸Ù"]),
        axis=1
    )
    df["Ø§Ø³Ù…_Ù†Ù‡Ø§Ø¦ÙŠ"] = df["Ø§Ø³Ù…_Ù†Ù‡Ø§Ø¦ÙŠ"].fillna("").astype(str).str.strip()
    return df

@st.cache_data
def load_data_from_excel(path: Path) -> pd.DataFrame:
    df = pd.read_excel(path)
    return load_data_df(df)

@st.cache_data
def load_data_from_uploaded(file_bytes: bytes) -> pd.DataFrame:
    df = pd.read_excel(file_bytes)
    return load_data_df(df)

# =========================
# Helpers
# =========================
def fmt_money(x):
    if x is None or pd.isna(x):
        return "-"
    x = float(x)
    sign = "-" if x < 0 else ""
    x = abs(x)
    if x >= 1e9:  return f"{sign}{x/1e9:.2f}B"
    if x >= 1e6:  return f"{sign}{x/1e6:.2f}M"
    if x >= 1e3:  return f"{sign}{x/1e3:.2f}K"
    return f"{sign}{x:.0f}"

def consecutive_positive_days(df_sym):
    s = df_sym.sort_values("Ø§Ù„ØªØ§Ø±ÙŠØ®")["ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©"].fillna(0).tolist()
    cnt = 0
    for v in reversed(s):
        if v > 0:
            cnt += 1
        else:
            break
    return cnt

def style_net_column(v):
    if pd.isna(v):
        return ""
    if v > 0:
        return "color: #00C853; font-weight: 800;"
    if v < 0:
        return "color: #D50000; font-weight: 800;"
    return ""

def weighted_mean(values, weights):
    v = pd.to_numeric(values, errors="coerce")
    w = pd.to_numeric(weights, errors="coerce")
    mask = v.notna() & w.notna() & (w > 0)
    if mask.sum() == 0:
        return None
    return float((v[mask] * w[mask]).sum() / w[mask].sum())

def get_change_metric(scope_df: pd.DataFrame, mode: str):
    if "Ø§Ù„ØªØºÙŠØ± %" not in scope_df.columns or scope_df.empty:
        return "-", None

    if mode == "Ø¢Ø®Ø± Ø¬Ù„Ø³Ø©":
        last_row = scope_df.sort_values("Ø§Ù„ØªØ§Ø±ÙŠØ®").iloc[-1]
        v = last_row.get("Ø§Ù„ØªØºÙŠØ± %")
        return ("-" if pd.isna(v) else f"{v:.2f}%"), None

    if mode == "Ù…ØªÙˆØ³Ø·":
        v = scope_df["Ø§Ù„ØªØºÙŠØ± %"].mean()
        if pd.isna(v):
            return "-", None
        last_v = scope_df.sort_values("Ø§Ù„ØªØ§Ø±ÙŠØ®").iloc[-1].get("Ø§Ù„ØªØºÙŠØ± %")
        delta = f"Ø¢Ø®Ø± Ø¬Ù„Ø³Ø©: {last_v:.2f}%" if not pd.isna(last_v) else None
        return f"{v:.2f}%", delta

    if mode == "Ù…ØªÙˆØ³Ø· Ù…Ø±Ø¬Ù‘Ø­ (Ù‚ÙŠÙ…Ø© Ø§Ù„ØªØ¯Ø§ÙˆÙ„)":
        if "Ù‚ÙŠÙ…Ø© Ø§Ù„ØªØ¯Ø§ÙˆÙ„" not in scope_df.columns:
            return "-", None
        v = weighted_mean(scope_df["Ø§Ù„ØªØºÙŠØ± %"], scope_df["Ù‚ÙŠÙ…Ø© Ø§Ù„ØªØ¯Ø§ÙˆÙ„"])
        if v is None:
            return "-", None
        last_v = scope_df.sort_values("Ø§Ù„ØªØ§Ø±ÙŠØ®").iloc[-1].get("Ø§Ù„ØªØºÙŠØ± %")
        delta = f"Ø¢Ø®Ø± Ø¬Ù„Ø³Ø©: {last_v:.2f}%" if not pd.isna(last_v) else None
        return f"{v:.2f}%", delta

    return "-", None

def add_watermark(fig, text=COPYRIGHT):
    # Ø¨ØµÙ…Ø© Ø®ÙÙŠÙØ© Ø¹Ù„Ù‰ Ø§Ù„Ø±Ø³ÙˆÙ…Ø§Øª
    fig.add_annotation(
        text=text,
        xref="paper", yref="paper",
        x=0.99, y=0.01,
        xanchor="right",
        yanchor="bottom",
        showarrow=False,
        opacity=0.35,
        font=dict(size=12),
    )
    return fig

# =========================
# Header
# =========================
st.title(f"ğŸ“Š {APP_TITLE}")
st.caption(f"{APP_SUBTITLE} â€” Version {APP_VERSION} â€” {COPYRIGHT}")

# =========================
# Load data (local file or upload)
# =========================
df = None
if DATA_PATH.exists():
    df = load_data_from_excel(DATA_PATH)
else:
    st.warning("Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (liquidity_all.xlsx) ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯. Ø§Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù Ù…Ù† Ù‡Ù†Ø§ (Ù…Ù†Ø§Ø³Ø¨ Ù„Ù„Ù€ Cloud).")
    up = st.file_uploader("Upload liquidity_all.xlsx", type=["xlsx"])
    if up is None:
        st.stop()
    df = load_data_from_uploaded(up)

# =========================
# Top filters
# =========================
min_d, max_d = df["Ø§Ù„ØªØ§Ø±ÙŠØ®"].min(), df["Ø§Ù„ØªØ§Ø±ÙŠØ®"].max()

c1, c2, c3 = st.columns([2, 2, 3])
with c1:
    start_date = st.date_input("Ù…Ù† ØªØ§Ø±ÙŠØ®", value=min_d.date(), min_value=min_d.date(), max_value=max_d.date())
with c2:
    end_date = st.date_input("Ø¥Ù„Ù‰ ØªØ§Ø±ÙŠØ®", value=max_d.date(), min_value=min_d.date(), max_value=max_d.date())
with c3:
    symbols = sorted(df["Ø§Ù„Ø±Ù…Ø²"].dropna().unique().tolist())
    selected_symbol = st.selectbox("Ø§Ø®ØªØ± Ø³Ù‡Ù… Ù„Ù„ØªÙØ§ØµÙŠÙ„", options=["(Ø§Ù„Ø³ÙˆÙ‚)"] + symbols)

base_dff = df[(df["Ø§Ù„ØªØ§Ø±ÙŠØ®"].dt.date >= start_date) & (df["Ø§Ù„ØªØ§Ø±ÙŠØ®"].dt.date <= end_date)].copy()

# =========================
# Tabs (Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø¢Ø®Ø± Ø­Ø§Ø¬Ø© Ø¨ØµØ±ÙŠÙ‹Ø§) + Help/About/README
# =========================
tab_market, tab_watch, tab_details, tab_history, tab_help, tab_about, tab_readme, tab_settings = st.tabs(
    ["ğŸ“ˆ Ø§Ù„Ø³ÙˆÙ‚", "ğŸ“Œ Ù…Ø±Ø§Ù‚Ø¨ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©", "ğŸ” ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø³Ù‡Ù…", "ğŸ“Š ØªØ§Ø±ÙŠØ® Ø§Ù„Ø³ÙŠÙˆÙ„Ø©", "â“ Help", "â„¹ï¸ About", "ğŸ“„ README", "âš™ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª"]
)

# =========================
# SETTINGS TAB (Ø¢Ø®Ø± Tab Ø¨ØµØ±ÙŠÙ‹Ø§ - Ù„ÙƒÙ†Ù‡ ÙŠØªÙ†ÙØ° Ø¹Ø§Ø¯ÙŠ)
# =========================
with tab_settings:
    st.header("âš™ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¹Ø±Ø¶")

    mode = st.radio(
        "ÙˆØ¶Ø¹ Ø§Ù„Ø­Ø³Ø§Ø¨",
        ["ÙØªØ±Ø© Ù…Ø®ØµØµØ©", "Ø¢Ø®Ø± 10 Ø¬Ù„Ø³Ø§Øª", "Ø¢Ø®Ø± Ø¬Ù„Ø³Ø© ÙÙ‚Ø·"],
        horizontal=True,
        index=0,
        key="mode_calc"
    )

    net_filter = st.radio(
        "ÙÙ„ØªØ± Ø§ØªØ¬Ø§Ù‡ ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©",
        ["Ø§Ù„ÙƒÙ„", "ØµØ§ÙÙŠ Ù…ÙˆØ¬Ø¨ ÙÙ‚Ø·", "ØµØ§ÙÙŠ Ø³Ø§Ù„Ø¨ ÙÙ‚Ø·"],
        horizontal=True,
        index=0,
        key="net_filter"
    )

    min_liq_pct = st.slider(
        "ÙÙ„ØªØ± Ù†Ø³Ø¨Ø© Ù…Ø®Ø·Ø· Ø§Ù„Ø³ÙŠÙˆÙ„Ø© (â‰¥)",
        0, 100, 0, 5,
        key="min_liq_pct"
    )

    change_mode = st.selectbox(
        "Ø¹Ø±Ø¶ % Ø§Ù„ØªØºÙŠØ± ÙÙŠ Ø§Ù„Ù…Ù„Ø®Øµ",
        ["Ø¢Ø®Ø± Ø¬Ù„Ø³Ø©", "Ù…ØªÙˆØ³Ø·", "Ù…ØªÙˆØ³Ø· Ù…Ø±Ø¬Ù‘Ø­ (Ù‚ÙŠÙ…Ø© Ø§Ù„ØªØ¯Ø§ÙˆÙ„)"],
        index=1,
        key="change_mode"
    )

    st.caption("Ù…Ù„Ø§Ø­Ø¸Ø©: Ø§Ù„ØªØ§Ø¨Ø§Øª Ø§Ù„Ø£Ø®Ø±Ù‰ ØªØ³ØªØ®Ø¯Ù… Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø¯ÙŠ ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§.")

# =========================
# Apply settings to dff
# =========================
dff = base_dff.copy()

if mode == "Ø¢Ø®Ø± 10 Ø¬Ù„Ø³Ø§Øª":
    last_dates = sorted(dff["Ø§Ù„ØªØ§Ø±ÙŠØ®"].dt.date.dropna().unique().tolist())
    last_dates = last_dates[-10:] if len(last_dates) > 10 else last_dates
    dff = dff[dff["Ø§Ù„ØªØ§Ø±ÙŠØ®"].dt.date.isin(last_dates)].copy()

elif mode == "Ø¢Ø®Ø± Ø¬Ù„Ø³Ø© ÙÙ‚Ø·":
    if not dff.empty:
        last_day = dff["Ø§Ù„ØªØ§Ø±ÙŠØ®"].max()
        dff = dff[dff["Ø§Ù„ØªØ§Ø±ÙŠØ®"] == last_day].copy()

if "Ù†Ø³Ø¨Ø© Ù…Ø®Ø·Ø· Ø§Ù„Ø³ÙŠÙˆÙ„Ø©" in dff.columns and min_liq_pct > 0:
    dff = dff[dff["Ù†Ø³Ø¨Ø© Ù…Ø®Ø·Ø· Ø§Ù„Ø³ÙŠÙˆÙ„Ø©"] >= min_liq_pct].copy()

if net_filter == "ØµØ§ÙÙŠ Ù…ÙˆØ¬Ø¨ ÙÙ‚Ø·":
    dff = dff[dff["ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©"] > 0].copy()
elif net_filter == "ØµØ§ÙÙŠ Ø³Ø§Ù„Ø¨ ÙÙ‚Ø·":
    dff = dff[dff["ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©"] < 0].copy()

# Ù†Ø·Ø§Ù‚ Ø§Ù„Ø¹Ø±Ø¶ (Ø³ÙˆÙ‚ Ø£Ùˆ Ø³Ù‡Ù…)
if selected_symbol != "(Ø§Ù„Ø³ÙˆÙ‚)":
    scope_df = dff[dff["Ø§Ù„Ø±Ù…Ø²"] == selected_symbol].copy()
    nm = scope_df["Ø§Ø³Ù…_Ù†Ù‡Ø§Ø¦ÙŠ"].iloc[0] if (not scope_df.empty and "Ø§Ø³Ù…_Ù†Ù‡Ø§Ø¦ÙŠ" in scope_df.columns) else ""
    scope_label = f"{selected_symbol} - {nm}".strip(" -")
else:
    scope_df = dff
    scope_label = "Ø§Ù„Ø³ÙˆÙ‚"

# =========================
# TAB: Help
# =========================
with tab_help:
    st.header("â“ Help")
    st.markdown(
        """
### Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
- **Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„ÙØªØ±Ø©**: Ù…Ù† Ø£Ø¹Ù„Ù‰ Ø§Ù„ØµÙØ­Ø© (Ù…Ù†/Ø¥Ù„Ù‰).
- **Ø§Ø®ØªÙŠØ§Ø± Ø³Ù‡Ù…**: Ù…Ù† Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£Ø³Ù‡Ù… Ù„Ø¹Ø±Ø¶ ØªÙØ§ØµÙŠÙ„Ù‡.
- **Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª**: Ù…Ù† Tab (âš™ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª) Ù„ØªØ­Ø¯ÙŠØ¯:
  - ÙØªØ±Ø© Ù…Ø®ØµØµØ© / Ø¢Ø®Ø± 10 Ø¬Ù„Ø³Ø§Øª / Ø¢Ø®Ø± Ø¬Ù„Ø³Ø© ÙÙ‚Ø·
  - ÙÙ„ØªØ±Ø© ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø© (Ù…ÙˆØ¬Ø¨ ÙÙ‚Ø· / Ø³Ø§Ù„Ø¨ ÙÙ‚Ø·)
  - ÙÙ„ØªØ±Ø© Ù†Ø³Ø¨Ø© Ù…Ø®Ø·Ø· Ø§Ù„Ø³ÙŠÙˆÙ„Ø©

### Ù…Ù„Ø§Ø­Ø¸Ø§Øª
- ØªÙ… Ø¥Ø¶Ø§ÙØ© ØªØµØ­ÙŠØ­ ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù„Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© (OCR cleanup) + Ù‚Ø§Ù…ÙˆØ³ Ø±Ù…ÙˆØ² (Overrides).
- Ø§Ù„Ø£Ù„ÙˆØ§Ù†: **Ø£Ø®Ø¶Ø± = ØµØ§ÙÙŠ Ù…ÙˆØ¬Ø¨**ØŒ **Ø£Ø­Ù…Ø± = ØµØ§ÙÙŠ Ø³Ø§Ù„Ø¨**.
"""
    )
    st.info(DISCLAIMER)

# =========================
# TAB: About
# =========================
with tab_about:
    st.header("â„¹ï¸ About")
    st.markdown(
        f"""
**{APP_TITLE}** â€” *{APP_SUBTITLE}*  
Version: `{APP_VERSION}`

**Owner / Author:** {AUTHOR}  
**Copyright:** {COPYRIGHT}

### Intellectual Property
- Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ù…Ø³Ù…ÙˆØ­ Ø¹Ø¨Ø± Ø§Ù„Ø±Ø§Ø¨Ø· ÙÙ‚Ø·.
- ÙŠÙ…Ù†Ø¹ Ù†Ø³Ø®/ØªØ¹Ø¯ÙŠÙ„/Ø¥Ø¹Ø§Ø¯Ø© ØªÙˆØ²ÙŠØ¹ Ø§Ù„ÙƒÙˆØ¯ Ø£Ùˆ Ø£ÙŠ Ø¬Ø²Ø¡ Ù…Ù†Ù‡ Ø¨Ø¯ÙˆÙ† Ø¥Ø°Ù† ÙƒØªØ§Ø¨ÙŠ Ù…Ù† Ø§Ù„Ù…Ø§Ù„Ùƒ.

### Contact
- Email: [{EMAIL}](mailto:{EMAIL})
- WhatsApp: {WHATSAPP_URL}
- Telegram: {TELEGRAM_URL}

**Disclaimer:** {DISCLAIMER}
"""
    )

# =========================
# TAB: README (Ø¹Ø±Ø¶ Ù…Ù† Ø§Ù„Ù…Ù„Ù + ØªÙ†Ø²ÙŠÙ„)
# =========================
with tab_readme:
    st.header("ğŸ“„ README Ø¯Ø§Ø®Ù„ Ø§Ù„Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯")

    if README_PATH.exists():
        readme_text = README_PATH.read_text(encoding="utf-8")
        st.download_button(
            "â¬‡ï¸ ØªØ­Ù…ÙŠÙ„ README.md",
            data=readme_text,
            file_name="README.md",
            mime="text/markdown"
        )
        st.markdown(readme_text)
    else:
        st.warning("Ø§Ù„Ù…Ù„Ù README.md ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø¬Ø§Ù†Ø¨ app.py. Ø¶Ø¹ README.md ÙÙŠ Ù†ÙØ³ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹.")
        st.code(str(README_PATH))

# =========================
# TAB 1: Market/Symbol summary
# =========================
with tab_market:
    st.header(f"Ù…Ù„Ø®Øµ ({scope_label})")

    if scope_df.empty:
        st.warning("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ø³Ø¨ Ø§Ù„ÙÙ„Ø§ØªØ± Ø§Ù„Ù…Ø®ØªØ§Ø±Ø©.")
    else:
        total_in = scope_df["Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ø§Ù„Ø¯Ø§Ø®Ù„Ø©"].sum()
        total_out = scope_df["Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ø§Ù„Ø®Ø§Ø±Ø¬Ø©"].sum()
        net = scope_df["ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©"].sum()
        change_value, change_delta = get_change_metric(scope_df, change_mode)

        m1, m2, m3, m4 = st.columns(4)
        m1.metric("Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ø§Ù„Ø¯Ø§Ø®Ù„Ø©", fmt_money(total_in))
        m2.metric("Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ø§Ù„Ø®Ø§Ø±Ø¬Ø©", fmt_money(total_out))
        m3.metric("ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©", fmt_money(net))
        m4.metric("% Ø§Ù„ØªØºÙŠØ±", change_value, delta=change_delta)

        pie_df = pd.DataFrame({
            "Ø§Ù„Ù†ÙˆØ¹": ["Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ø§Ù„Ø¯Ø§Ø®Ù„Ø©", "Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ø§Ù„Ø®Ø§Ø±Ø¬Ø©"],
            "Ø§Ù„Ù‚ÙŠÙ…Ø©": [total_in, total_out]
        })
        fig_pie = px.pie(pie_df, names="Ø§Ù„Ù†ÙˆØ¹", values="Ø§Ù„Ù‚ÙŠÙ…Ø©", hole=0.6)
        fig_pie.update_traces(
            textposition="outside",
            textinfo="percent+label",
            marker=dict(colors=["#00C853", "#D50000"])
        )
        fig_pie = add_watermark(fig_pie)

        daily_net = (
            scope_df.assign(Ø§Ù„ØªØ§Ø±ÙŠØ®=scope_df["Ø§Ù„ØªØ§Ø±ÙŠØ®"].dt.date)
                    .groupby("Ø§Ù„ØªØ§Ø±ÙŠØ®", as_index=False)["ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©"].sum()
        )
        daily_net["Ø§Ù„Ø¥Ø´Ø§Ø±Ø©"] = daily_net["ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©"].apply(lambda x: "Ù…ÙˆØ¬Ø¨" if x >= 0 else "Ø³Ø§Ù„Ø¨")
        fig_market = px.bar(
            daily_net, x="Ø§Ù„ØªØ§Ø±ÙŠØ®", y="ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©",
            color="Ø§Ù„Ø¥Ø´Ø§Ø±Ø©",
            color_discrete_map={"Ù…ÙˆØ¬Ø¨": "#00C853", "Ø³Ø§Ù„Ø¨": "#D50000"},
        )
        fig_market.update_layout(legend_title_text="")
        fig_market = add_watermark(fig_market)

        left, right = st.columns([1, 1])
        with left:
            st.plotly_chart(
                fig_pie,
                use_container_width=True,
                key=f"pie_{selected_symbol}_{mode}_{net_filter}_{min_liq_pct}_{start_date}_{end_date}"
            )
        with right:
            st.plotly_chart(
                fig_market,
                use_container_width=True,
                key=f"market_{selected_symbol}_{mode}_{net_filter}_{min_liq_pct}_{start_date}_{end_date}"
            )

# =========================
# TAB 2: Watchlist ranking
# =========================
with tab_watch:
    st.header("Ù…Ø±Ø§Ù‚Ø¨ Ø§Ù„Ø³ÙŠÙˆÙ„Ø© (ØªØ±ØªÙŠØ¨ Ø§Ù„Ø£Ø³Ù‡Ù…)")

    if dff.empty:
        st.warning("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ø³Ø¨ Ø§Ù„ÙÙ„Ø§ØªØ± Ø§Ù„Ù…Ø®ØªØ§Ø±Ø©.")
    else:
        # Ù†Ø¬Ù…Ø¹ Ø¹Ù„Ù‰ Ø§Ù„Ø±Ù…Ø² ÙÙ‚Ø· Ù„Ø¶Ù…Ø§Ù† Ø¹Ø¯Ù… ØªÙƒØ±Ø§Ø± Ø§Ù„Ø§Ø³Ù… Ø¨Ø³Ø¨Ø¨ OCR
        def most_common_name(x):
            x = x.dropna().astype(str).str.strip()
            if x.empty:
                return ""
            return x.value_counts().idxmax()

        rank = (
            dff.groupby("Ø§Ù„Ø±Ù…Ø²", as_index=False)
               .agg({
                   "Ø§Ø³Ù…_Ù†Ù‡Ø§Ø¦ÙŠ": most_common_name,
                   "ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©": "sum",
                   "Ù‚ÙŠÙ…Ø© Ø§Ù„ØªØ¯Ø§ÙˆÙ„": "sum",
                   "Ø§Ù„ØªØºÙŠØ± %": "mean"
               })
        )

        consec_map = {}
        for sym in rank["Ø§Ù„Ø±Ù…Ø²"].tolist():
            sym_df = dff[dff["Ø§Ù„Ø±Ù…Ø²"] == sym]
            consec_map[sym] = consecutive_positive_days(sym_df)
        rank["Ø£ÙŠØ§Ù… Ù…ØªØªØ§Ù„ÙŠØ© (ØµØ§ÙÙŠ Ù…ÙˆØ¬Ø¨)"] = rank["Ø§Ù„Ø±Ù…Ø²"].map(consec_map).fillna(0).astype(int)

        rank = rank.sort_values("ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©", ascending=False)

        top_n = st.slider("Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø³Ù‡Ù… Ø§Ù„Ù…Ø¹Ø±ÙˆØ¶Ø©", 10, 200, 30, 10, key="topn_watch")

        show_raw = rank.head(top_n).copy()
        show_raw = show_raw.rename(columns={"Ø§Ø³Ù…_Ù†Ù‡Ø§Ø¦ÙŠ": "Ø§Ù„Ø¥Ø³Ù…"})

        styler = (
            show_raw.style
            .applymap(style_net_column, subset=["ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©"])
            .format({
                "ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©": lambda v: fmt_money(v),
                "Ù‚ÙŠÙ…Ø© Ø§Ù„ØªØ¯Ø§ÙˆÙ„": lambda v: fmt_money(v),
                "Ø§Ù„ØªØºÙŠØ± %": "{:.2f}".format
            })
        )

        st.dataframe(styler, use_container_width=True, hide_index=True)

# =========================
# TAB 3: Symbol details
# =========================
with tab_details:
    st.header("ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø³Ù‡Ù…")

    if selected_symbol == "(Ø§Ù„Ø³ÙˆÙ‚)":
        st.info("Ø§Ø®ØªØ± Ø³Ù‡Ù… Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„Ø£Ø¹Ù„Ù‰ Ù„Ø¹Ø±Ø¶ Ø§Ù„ØªÙØ§ØµÙŠÙ„.")
    elif scope_df.empty:
        st.warning("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø³Ù‡Ù… Ø­Ø³Ø¨ Ø§Ù„ÙÙ„Ø§ØªØ± Ø§Ù„Ù…Ø®ØªØ§Ø±Ø©.")
    else:
        sym_df = scope_df.copy().sort_values("Ø§Ù„ØªØ§Ø±ÙŠØ®")

        c1, c2 = st.columns([2, 1])
        with c1:
            sym_daily = (
                sym_df.assign(Ø§Ù„ØªØ§Ø±ÙŠØ®=sym_df["Ø§Ù„ØªØ§Ø±ÙŠØ®"].dt.date)
                      .groupby("Ø§Ù„ØªØ§Ø±ÙŠØ®", as_index=False)["ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©"].sum()
            )
            sym_daily["Ø§Ù„Ø¥Ø´Ø§Ø±Ø©"] = sym_daily["ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©"].apply(lambda x: "Ù…ÙˆØ¬Ø¨" if x >= 0 else "Ø³Ø§Ù„Ø¨")
            fig_sym = px.bar(
                sym_daily,
                x="Ø§Ù„ØªØ§Ø±ÙŠØ®",
                y="ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©",
                color="Ø§Ù„Ø¥Ø´Ø§Ø±Ø©",
                color_discrete_map={"Ù…ÙˆØ¬Ø¨": "#00C853", "Ø³Ø§Ù„Ø¨": "#D50000"},
            )
            fig_sym.update_layout(legend_title_text="")
            fig_sym = add_watermark(fig_sym)

            st.plotly_chart(
                fig_sym, use_container_width=True,
                key=f"sym_{selected_symbol}_{mode}_{net_filter}_{min_liq_pct}_{start_date}_{end_date}"
            )

        with c2:
            st.write("**Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ÙØªØ±Ø©**")
            st.metric("Ø§Ù„Ø¥Ø³Ù…", sym_df["Ø§Ø³Ù…_Ù†Ù‡Ø§Ø¦ÙŠ"].iloc[0] if "Ø§Ø³Ù…_Ù†Ù‡Ø§Ø¦ÙŠ" in sym_df.columns else "-")
            st.metric("ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©", fmt_money(sym_df["ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©"].sum()))
            if "Ø§Ù„ØªØºÙŠØ± %" in sym_df.columns:
                st.metric("Ù…ØªÙˆØ³Ø· Ø§Ù„ØªØºÙŠØ± %", f'{sym_df["Ø§Ù„ØªØºÙŠØ± %"].mean():.2f}%')
            if "Ø¢Ø®Ø± Ø³Ø¹Ø±" in sym_df.columns and not sym_df.empty:
                st.metric("Ø¢Ø®Ø± Ø³Ø¹Ø± (Ø¢Ø®Ø± Ø¬Ù„Ø³Ø©)", f'{sym_df.iloc[-1]["Ø¢Ø®Ø± Ø³Ø¹Ø±"]:.2f}')
            st.metric("Ø£ÙŠØ§Ù… Ù…ØªØªØ§Ù„ÙŠØ© ØµØ§ÙÙŠ Ù…ÙˆØ¬Ø¨", str(consecutive_positive_days(sym_df)))

        st.write("**ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø¬Ù„Ø³Ø§Øª**")
        view_cols = [
            "Ø§Ù„ØªØ§Ø±ÙŠØ®", "Ø§Ù„Ø±Ù…Ø²", "Ø§Ø³Ù…_Ù†Ù‡Ø§Ø¦ÙŠ",
            "Ø¢Ø®Ø± Ø³Ø¹Ø±", "Ø§Ù„ØªØºÙŠØ± %",
            "Ù‚ÙŠÙ…Ø© Ø§Ù„ØªØ¯Ø§ÙˆÙ„", "Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ø§Ù„Ø¯Ø§Ø®Ù„Ø©", "Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ø§Ù„Ø®Ø§Ø±Ø¬Ø©",
            "ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©", "Ù†Ø³Ø¨Ø© Ù…Ø®Ø·Ø· Ø§Ù„Ø³ÙŠÙˆÙ„Ø©",
            "Ø§Ù„Ù…ØµØ¯Ø±"
        ]
        view_cols = [c for c in view_cols if c in sym_df.columns]
        show_table = sym_df[view_cols].rename(columns={"Ø§Ø³Ù…_Ù†Ù‡Ø§Ø¦ÙŠ": "Ø§Ù„Ø¥Ø³Ù…"})
        st.dataframe(show_table.sort_values("Ø§Ù„ØªØ§Ø±ÙŠØ®", ascending=False), use_container_width=True, hide_index=True)

# =========================
# TAB 4: History
# =========================
with tab_history:
    st.header(f"ØªØ§Ø±ÙŠØ® Ø§Ù„Ø³ÙŠÙˆÙ„Ø© ({scope_label})")

    if scope_df.empty:
        st.warning("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ø³Ø¨ Ø§Ù„ÙÙ„Ø§ØªØ± Ø§Ù„Ù…Ø®ØªØ§Ø±Ø©.")
    else:
        hist = (
            scope_df.assign(Ø§Ù„ØªØ§Ø±ÙŠØ®=scope_df["Ø§Ù„ØªØ§Ø±ÙŠØ®"].dt.date)
                    .groupby("Ø§Ù„ØªØ§Ø±ÙŠØ®", as_index=False)
                    .agg({
                        "ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©": "sum",
                        "Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ø§Ù„Ø¯Ø§Ø®Ù„Ø©": "sum",
                        "Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ø§Ù„Ø®Ø§Ø±Ø¬Ø©": "sum",
                        "Ø§Ù„ØªØºÙŠØ± %": "mean",
                        "Ø¢Ø®Ø± Ø³Ø¹Ø±": "last" if "Ø¢Ø®Ø± Ø³Ø¹Ø±" in scope_df.columns else "size"
                    })
        ).sort_values("Ø§Ù„ØªØ§Ø±ÙŠØ®")

        hist["Ø§Ù„Ø¥Ø´Ø§Ø±Ø©"] = hist["ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©"].apply(lambda x: "Ù…ÙˆØ¬Ø¨" if x >= 0 else "Ø³Ø§Ù„Ø¨")
        fig_hist = px.bar(
            hist, x="Ø§Ù„ØªØ§Ø±ÙŠØ®", y="ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©",
            color="Ø§Ù„Ø¥Ø´Ø§Ø±Ø©",
            color_discrete_map={"Ù…ÙˆØ¬Ø¨": "#00C853", "Ø³Ø§Ù„Ø¨": "#D50000"},
        )
        fig_hist.update_layout(legend_title_text="")
        fig_hist = add_watermark(fig_hist)

        st.plotly_chart(
            fig_hist, use_container_width=True,
            key=f"hist_{selected_symbol}_{mode}_{net_filter}_{min_liq_pct}_{start_date}_{end_date}"
        )

        table_cols = ["Ø§Ù„ØªØ§Ø±ÙŠØ®", "Ø¢Ø®Ø± Ø³Ø¹Ø±", "Ø§Ù„ØªØºÙŠØ± %", "ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©", "Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ø§Ù„Ø¯Ø§Ø®Ù„Ø©", "Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ø§Ù„Ø®Ø§Ø±Ø¬Ø©"]
        table_cols = [c for c in table_cols if c in hist.columns]
        hist_show = hist[table_cols].copy()

        if "Ø§Ù„ØªØºÙŠØ± %" in hist_show.columns:
            hist_show["Ø§Ù„ØªØºÙŠØ± %"] = hist_show["Ø§Ù„ØªØºÙŠØ± %"].round(2)

        for c in ["ØµØ§ÙÙŠ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©", "Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ø§Ù„Ø¯Ø§Ø®Ù„Ø©", "Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ø§Ù„Ø®Ø§Ø±Ø¬Ø©"]:
            if c in hist_show.columns:
                hist_show[c] = hist_show[c].apply(fmt_money)

        st.dataframe(hist_show.sort_values("Ø§Ù„ØªØ§Ø±ÙŠØ®", ascending=False), use_container_width=True, hide_index=True)

# =========================
# Footer (Ø­Ù‚ÙˆÙ‚ + Disclaimer)
# =========================
st.markdown(
    f"""
    <hr>
    <div style='text-align:center; opacity:0.85; font-weight:700;'>
        {COPYRIGHT} â€” {DISCLAIMER}<br>
        Contact: <a href="mailto:{EMAIL}">{EMAIL}</a> |
        <a href="{WHATSAPP_URL}" target="_blank">WhatsApp</a> |
        <a href="{TELEGRAM_URL}" target="_blank">Telegram</a>
    </div>
    """,
    unsafe_allow_html=True
)

